{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayankgupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "/Users/mayankgupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mayankgupta/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/mayankgupta/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 1.3008 - accuracy: 0.4645 - val_loss: 1.0891 - val_accuracy: 0.5565\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.9056 - accuracy: 0.6171 - val_loss: 0.8277 - val_accuracy: 0.5942\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.7434 - accuracy: 0.6549 - val_loss: 0.7569 - val_accuracy: 0.6230\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.6725 - accuracy: 0.6800 - val_loss: 0.6941 - val_accuracy: 0.6651\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.6236 - accuracy: 0.7116 - val_loss: 0.6568 - val_accuracy: 0.7326\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.5866 - accuracy: 0.7333 - val_loss: 0.7696 - val_accuracy: 0.6763\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.5055 - accuracy: 0.7748 - val_loss: 0.6162 - val_accuracy: 0.7272\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.4769 - accuracy: 0.7791 - val_loss: 0.5323 - val_accuracy: 0.7465\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.4243 - accuracy: 0.7979 - val_loss: 0.6893 - val_accuracy: 0.7167\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4033 - accuracy: 0.8096 - val_loss: 0.5631 - val_accuracy: 0.7326\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.3785 - accuracy: 0.8391 - val_loss: 0.5226 - val_accuracy: 0.7937\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.3327 - accuracy: 0.8791 - val_loss: 0.5721 - val_accuracy: 0.8694\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.2857 - accuracy: 0.9132 - val_loss: 0.4536 - val_accuracy: 0.8812\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.2537 - accuracy: 0.9207 - val_loss: 0.5414 - val_accuracy: 0.8748\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.2421 - accuracy: 0.9293 - val_loss: 0.4205 - val_accuracy: 0.8968\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.2077 - accuracy: 0.9331 - val_loss: 0.4868 - val_accuracy: 0.8785\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1950 - accuracy: 0.9384 - val_loss: 0.5625 - val_accuracy: 0.8833\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1844 - accuracy: 0.9419 - val_loss: 0.6079 - val_accuracy: 0.8738\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1846 - accuracy: 0.9414 - val_loss: 0.4497 - val_accuracy: 0.8999\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1701 - accuracy: 0.9459 - val_loss: 0.5215 - val_accuracy: 0.8795\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1723 - accuracy: 0.9450 - val_loss: 0.4698 - val_accuracy: 0.8887\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1813 - accuracy: 0.9448 - val_loss: 0.4783 - val_accuracy: 0.8795\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1579 - accuracy: 0.9465 - val_loss: 0.4126 - val_accuracy: 0.8968\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1754 - accuracy: 0.9448 - val_loss: 0.3679 - val_accuracy: 0.9111\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1827 - accuracy: 0.9425 - val_loss: 0.9810 - val_accuracy: 0.8426\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1565 - accuracy: 0.9489 - val_loss: 0.3639 - val_accuracy: 0.9043\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1508 - accuracy: 0.9484 - val_loss: 0.3858 - val_accuracy: 0.8996\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1461 - accuracy: 0.9470 - val_loss: 0.4374 - val_accuracy: 0.9013\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1558 - accuracy: 0.9449 - val_loss: 0.3596 - val_accuracy: 0.9043\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1712 - accuracy: 0.9433 - val_loss: 0.4166 - val_accuracy: 0.8955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x121401518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        27        0                   0   \n",
      "SITTING                  2      381       105        1                   1   \n",
      "STANDING                 0       86       446        0                   0   \n",
      "WALKING                  0        0         0      454                  15   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 419   \n",
      "WALKING_UPSTAIRS         0        7         0        4                  31   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                           27  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 429  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 299us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41655886096877154, 0.8954869508743286]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got approx. 89.54% accuracy and a loss of 0.4165\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.1 Update LSTM Layer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 1.2560 - accuracy: 0.4470 - val_loss: 1.1326 - val_accuracy: 0.4825\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.9495 - accuracy: 0.6081 - val_loss: 0.8467 - val_accuracy: 0.6912\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.8132 - accuracy: 0.6473 - val_loss: 0.8576 - val_accuracy: 0.6322\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.7342 - accuracy: 0.6933 - val_loss: 0.7157 - val_accuracy: 0.7458\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.5382 - accuracy: 0.7784 - val_loss: 0.5688 - val_accuracy: 0.7984\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.3811 - accuracy: 0.8579 - val_loss: 0.5755 - val_accuracy: 0.8480\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.3327 - accuracy: 0.8900 - val_loss: 0.5255 - val_accuracy: 0.8487\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.2582 - accuracy: 0.9129 - val_loss: 0.4217 - val_accuracy: 0.8873\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.2411 - accuracy: 0.9207 - val_loss: 0.3309 - val_accuracy: 0.9046\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1987 - accuracy: 0.9325 - val_loss: 0.4274 - val_accuracy: 0.8711\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.1965 - accuracy: 0.9334 - val_loss: 0.3487 - val_accuracy: 0.8731\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1784 - accuracy: 0.9357 - val_loss: 0.3973 - val_accuracy: 0.8951\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1763 - accuracy: 0.9391 - val_loss: 0.3849 - val_accuracy: 0.8979\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.1544 - accuracy: 0.9431 - val_loss: 0.4401 - val_accuracy: 0.9033\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1778 - accuracy: 0.9421 - val_loss: 0.2845 - val_accuracy: 0.9131\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.1749 - accuracy: 0.9392 - val_loss: 0.3084 - val_accuracy: 0.9087\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1582 - accuracy: 0.9436 - val_loss: 0.3808 - val_accuracy: 0.9108\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1480 - accuracy: 0.9487 - val_loss: 0.3502 - val_accuracy: 0.9138\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1504 - accuracy: 0.9484 - val_loss: 0.4116 - val_accuracy: 0.9036\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.1431 - accuracy: 0.9494 - val_loss: 0.2973 - val_accuracy: 0.9050\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1542 - accuracy: 0.9474 - val_loss: 0.3730 - val_accuracy: 0.9145\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1414 - accuracy: 0.9502 - val_loss: 0.3996 - val_accuracy: 0.9158\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1364 - accuracy: 0.9497 - val_loss: 0.3808 - val_accuracy: 0.9097\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1403 - accuracy: 0.9512 - val_loss: 0.3501 - val_accuracy: 0.9036\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1381 - accuracy: 0.9478 - val_loss: 0.4506 - val_accuracy: 0.9074\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1473 - accuracy: 0.9491 - val_loss: 0.4966 - val_accuracy: 0.9006\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1539 - accuracy: 0.9499 - val_loss: 0.3719 - val_accuracy: 0.9060\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1417 - accuracy: 0.9508 - val_loss: 0.3556 - val_accuracy: 0.9057\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1339 - accuracy: 0.9512 - val_loss: 0.4193 - val_accuracy: 0.8928\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1781 - accuracy: 0.9480 - val_loss: 0.3534 - val_accuracy: 0.9148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x62f5f3518>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 509        0        27        0                   0   \n",
      "SITTING                  0      365       126        0                   0   \n",
      "STANDING                 0       47       485        0                   0   \n",
      "WALKING                  0        0         0      459                  25   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 415   \n",
      "WALKING_UPSTAIRS         0        0         0        4                   4   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             1  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                           12  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 463  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 411us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35375094639873494, 0.9148286581039429]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updating LSTM layer from 32 to 64 increase the performance from 89.54% to 91.48% and reduce loss from 0.4165 to 0.3537"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.2 Update Dropout Rate</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2.1 Use 64 LSTM Layer and Dropout rate 0.7</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 1.2668 - accuracy: 0.4523 - val_loss: 1.0892 - val_accuracy: 0.5199\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.9252 - accuracy: 0.5966 - val_loss: 0.8212 - val_accuracy: 0.6244\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.7997 - accuracy: 0.6314 - val_loss: 0.8336 - val_accuracy: 0.6179\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.7036 - accuracy: 0.6722 - val_loss: 0.7824 - val_accuracy: 0.6216\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.6839 - accuracy: 0.7152 - val_loss: 0.6875 - val_accuracy: 0.7248\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.5654 - accuracy: 0.8130 - val_loss: 0.5180 - val_accuracy: 0.8273\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.4122 - accuracy: 0.8833 - val_loss: 0.6306 - val_accuracy: 0.8344\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4030 - accuracy: 0.8911 - val_loss: 1.1381 - val_accuracy: 0.7255\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.3243 - accuracy: 0.9074 - val_loss: 0.3398 - val_accuracy: 0.8979\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.2563 - accuracy: 0.9255 - val_loss: 0.3548 - val_accuracy: 0.8914\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.3041 - accuracy: 0.9191 - val_loss: 0.3749 - val_accuracy: 0.8867\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2504 - accuracy: 0.9257 - val_loss: 0.4726 - val_accuracy: 0.8761\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2604 - accuracy: 0.9285 - val_loss: 0.5156 - val_accuracy: 0.8663\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2206 - accuracy: 0.9331 - val_loss: 0.5957 - val_accuracy: 0.8612\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2023 - accuracy: 0.9324 - val_loss: 0.3542 - val_accuracy: 0.8877\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1955 - accuracy: 0.9385 - val_loss: 0.4524 - val_accuracy: 0.8836\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2068 - accuracy: 0.9372 - val_loss: 0.3065 - val_accuracy: 0.9016\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2338 - accuracy: 0.9358 - val_loss: 0.5638 - val_accuracy: 0.8860\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2166 - accuracy: 0.9362 - val_loss: 0.4288 - val_accuracy: 0.8863\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1724 - accuracy: 0.9431 - val_loss: 0.3221 - val_accuracy: 0.8985\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1826 - accuracy: 0.9438 - val_loss: 0.3623 - val_accuracy: 0.9043\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1771 - accuracy: 0.9430 - val_loss: 0.5044 - val_accuracy: 0.8931\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1904 - accuracy: 0.9426 - val_loss: 0.3908 - val_accuracy: 0.8951\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1789 - accuracy: 0.9426 - val_loss: 0.4822 - val_accuracy: 0.9118\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: nan - accuracy: 0.8251 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6300a6438>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                WALKING\n",
      "True                       \n",
      "LAYING                  537\n",
      "SITTING                 491\n",
      "STANDING                532\n",
      "WALKING                 496\n",
      "WALKING_DOWNSTAIRS      420\n",
      "WALKING_UPSTAIRS        471\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 286us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 0.16830675303936005]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With dropout 0.7 performance reduced drastically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2.2 Use 32 LSTM Layer and Dropout rate 0.7</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 1.4131 - accuracy: 0.4053 - val_loss: 1.2057 - val_accuracy: 0.5199\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 1.1514 - accuracy: 0.5004 - val_loss: 1.0854 - val_accuracy: 0.5212\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 1.0306 - accuracy: 0.5483 - val_loss: 0.9328 - val_accuracy: 0.6186\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.8413 - accuracy: 0.6328 - val_loss: 0.8098 - val_accuracy: 0.6403\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.7508 - accuracy: 0.6718 - val_loss: 0.7237 - val_accuracy: 0.6481\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.7021 - accuracy: 0.7036 - val_loss: 0.7130 - val_accuracy: 0.6977\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.6250 - accuracy: 0.7408 - val_loss: 0.6587 - val_accuracy: 0.7218\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.6306 - accuracy: 0.7467 - val_loss: 0.9023 - val_accuracy: 0.6749\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.5728 - accuracy: 0.7552 - val_loss: 0.6066 - val_accuracy: 0.7370\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.5665 - accuracy: 0.7582 - val_loss: 0.6308 - val_accuracy: 0.7122\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.5529 - accuracy: 0.7632 - val_loss: 0.8747 - val_accuracy: 0.7129\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.5008 - accuracy: 0.7757 - val_loss: 0.5392 - val_accuracy: 0.7513\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.5068 - accuracy: 0.7767 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.4965 - accuracy: 0.7792 - val_loss: 0.7161 - val_accuracy: 0.7313\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.6753 - accuracy: 0.7588 - val_loss: 0.5898 - val_accuracy: 0.7448\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.5031 - accuracy: 0.7777 - val_loss: 0.7619 - val_accuracy: 0.7245\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.4484 - accuracy: 0.7890 - val_loss: 0.6495 - val_accuracy: 0.7336\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4806 - accuracy: 0.7837 - val_loss: 0.5810 - val_accuracy: 0.7496\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.4920 - accuracy: 0.7875 - val_loss: 0.5989 - val_accuracy: 0.7855\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.4532 - accuracy: 0.8157 - val_loss: 0.5946 - val_accuracy: 0.8049\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 13s 2ms/step - loss: 0.4626 - accuracy: 0.8255 - val_loss: 0.4647 - val_accuracy: 0.8317\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 13s 2ms/step - loss: 0.4284 - accuracy: 0.8477 - val_loss: 0.4966 - val_accuracy: 0.8616\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 13s 2ms/step - loss: 0.4184 - accuracy: 0.8561 - val_loss: 0.4365 - val_accuracy: 0.8636\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 13s 2ms/step - loss: 0.3954 - accuracy: 0.8677 - val_loss: 0.4070 - val_accuracy: 0.8778\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 13s 2ms/step - loss: 0.3787 - accuracy: 0.8750 - val_loss: 0.4029 - val_accuracy: 0.8761\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.4372 - accuracy: 0.8668 - val_loss: 0.4681 - val_accuracy: 0.8619\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.4192 - accuracy: 0.8783 - val_loss: 0.4248 - val_accuracy: 0.8833\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4191 - accuracy: 0.8732 - val_loss: 1.1744 - val_accuracy: 0.7923\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.3634 - accuracy: 0.8832 - val_loss: 0.4041 - val_accuracy: 0.8907\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.3713 - accuracy: 0.8783 - val_loss: 0.5968 - val_accuracy: 0.8381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6309d69e8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      280       206        1                   1   \n",
      "STANDING                 0       34       489        4                   2   \n",
      "WALKING                  0        0         0      360                  33   \n",
      "WALKING_DOWNSTAIRS       0        0         0        3                 416   \n",
      "WALKING_UPSTAIRS         1        3         0       28                  24   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            3  \n",
      "STANDING                           3  \n",
      "WALKING                          103  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 415  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 243us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.596762544016313, 0.8381404876708984]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Better than 64 layer with same dropout 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2.3 Use 64 LSTM Layer and Dropout rate 0.6</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 1.2606 - accuracy: 0.4646 - val_loss: 1.0564 - val_accuracy: 0.5443\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.8792 - accuracy: 0.6002 - val_loss: 0.8393 - val_accuracy: 0.6179\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.7371 - accuracy: 0.6447 - val_loss: 0.7495 - val_accuracy: 0.6183\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.6515 - accuracy: 0.7088 - val_loss: 0.6700 - val_accuracy: 0.7048\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.4806 - accuracy: 0.8392 - val_loss: 0.5685 - val_accuracy: 0.8073\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.2974 - accuracy: 0.9057 - val_loss: 0.4664 - val_accuracy: 0.8660\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.2478 - accuracy: 0.9236 - val_loss: 0.4457 - val_accuracy: 0.8738\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.2243 - accuracy: 0.9282 - val_loss: 0.2996 - val_accuracy: 0.8863\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.2131 - accuracy: 0.9249 - val_loss: 0.5138 - val_accuracy: 0.8792\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.2012 - accuracy: 0.9329 - val_loss: 0.2673 - val_accuracy: 0.8979\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1872 - accuracy: 0.9353 - val_loss: 0.2656 - val_accuracy: 0.9101\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1965 - accuracy: 0.9366 - val_loss: 0.3882 - val_accuracy: 0.9080\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1710 - accuracy: 0.9404 - val_loss: 0.2497 - val_accuracy: 0.9091\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1621 - accuracy: 0.9408 - val_loss: 0.3737 - val_accuracy: 0.8921\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1517 - accuracy: 0.9456 - val_loss: 0.2366 - val_accuracy: 0.9165\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1870 - accuracy: 0.9423 - val_loss: 0.2972 - val_accuracy: 0.9036\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1612 - accuracy: 0.9418 - val_loss: 0.4051 - val_accuracy: 0.8890\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1619 - accuracy: 0.9434 - val_loss: 0.3921 - val_accuracy: 0.8941\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1394 - accuracy: 0.9493 - val_loss: 0.5242 - val_accuracy: 0.8985\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1573 - accuracy: 0.9467 - val_loss: 0.3529 - val_accuracy: 0.9097\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1615 - accuracy: 0.9499 - val_loss: 0.7128 - val_accuracy: 0.8789\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1429 - accuracy: 0.9518 - val_loss: 0.3295 - val_accuracy: 0.9223\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1548 - accuracy: 0.9479 - val_loss: 0.5361 - val_accuracy: 0.9063\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1543 - accuracy: 0.9467 - val_loss: 0.2969 - val_accuracy: 0.9016\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1431 - accuracy: 0.9471 - val_loss: 0.5244 - val_accuracy: 0.9050\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1457 - accuracy: 0.9499 - val_loss: 0.3353 - val_accuracy: 0.9186\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1532 - accuracy: 0.9510 - val_loss: 0.5023 - val_accuracy: 0.9074\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1357 - accuracy: 0.9514 - val_loss: 0.2958 - val_accuracy: 0.9152\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1368 - accuracy: 0.9490 - val_loss: 0.3224 - val_accuracy: 0.9189\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1569 - accuracy: 0.9467 - val_loss: 0.4957 - val_accuracy: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x631129d68>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 517        0        19        0                   0   \n",
      "SITTING                  0      416        74        0                   0   \n",
      "STANDING                 0       94       438        0                   0   \n",
      "WALKING                  0        0         0      495                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         0       15                 377   \n",
      "WALKING_UPSTAIRS         0        0         0       41                   3   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             1  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                28  \n",
      "WALKING_UPSTAIRS                 427  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 283us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4956902541945778, 0.9060060977935791]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Better than 0.7 dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2.4 Use 32 LSTM Layer and Dropout rate 0.6</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 1.3738 - accuracy: 0.3864 - val_loss: 1.3047 - val_accuracy: 0.4381\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 1.0837 - accuracy: 0.5292 - val_loss: 1.0199 - val_accuracy: 0.5565\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.8871 - accuracy: 0.6268 - val_loss: 0.8298 - val_accuracy: 0.6121\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.7479 - accuracy: 0.6549 - val_loss: 0.7888 - val_accuracy: 0.6149\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.7072 - accuracy: 0.6639 - val_loss: 0.8324 - val_accuracy: 0.6020\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.6625 - accuracy: 0.6814 - val_loss: 0.8694 - val_accuracy: 0.5979\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.6415 - accuracy: 0.7081 - val_loss: 0.7401 - val_accuracy: 0.6614\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.5871 - accuracy: 0.7678 - val_loss: 0.6918 - val_accuracy: 0.7754\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.4870 - accuracy: 0.8341 - val_loss: 0.7611 - val_accuracy: 0.7540\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.4380 - accuracy: 0.8558 - val_loss: 0.6525 - val_accuracy: 0.8022\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.4693 - accuracy: 0.8546 - val_loss: 0.5199 - val_accuracy: 0.8636\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.3959 - accuracy: 0.8878 - val_loss: 0.6564 - val_accuracy: 0.8290\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.3703 - accuracy: 0.8953 - val_loss: 0.5741 - val_accuracy: 0.8324\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.3400 - accuracy: 0.9029 - val_loss: 0.5634 - val_accuracy: 0.8497\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.3523 - accuracy: 0.8976 - val_loss: 0.6537 - val_accuracy: 0.8449\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.3631 - accuracy: 0.8946 - val_loss: 0.4173 - val_accuracy: 0.8789\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.3099 - accuracy: 0.9123 - val_loss: 0.6522 - val_accuracy: 0.8490\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.3181 - accuracy: 0.9066 - val_loss: 0.4997 - val_accuracy: 0.8748\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.2624 - accuracy: 0.9219 - val_loss: 0.5491 - val_accuracy: 0.8700\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.2779 - accuracy: 0.9229 - val_loss: 0.5618 - val_accuracy: 0.8850\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2645 - accuracy: 0.9272 - val_loss: 0.4384 - val_accuracy: 0.8941\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.3439 - accuracy: 0.9105 - val_loss: 0.4841 - val_accuracy: 0.8789\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2935 - accuracy: 0.9139 - val_loss: 0.5743 - val_accuracy: 0.8870\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2599 - accuracy: 0.9293 - val_loss: 0.4404 - val_accuracy: 0.8945\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.2976 - accuracy: 0.9149 - val_loss: 0.4465 - val_accuracy: 0.8836\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.2633 - accuracy: 0.9237 - val_loss: 0.4992 - val_accuracy: 0.8924\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.2649 - accuracy: 0.9261 - val_loss: 0.5707 - val_accuracy: 0.8711\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.2830 - accuracy: 0.9229 - val_loss: 0.4471 - val_accuracy: 0.8887\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2589 - accuracy: 0.9263 - val_loss: 0.4967 - val_accuracy: 0.8843\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.2628 - accuracy: 0.9279 - val_loss: 0.5602 - val_accuracy: 0.8812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x633723b70>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        24        0                   0   \n",
      "SITTING                  3      434        29        7                   0   \n",
      "STANDING                 0      135       379        1                   0   \n",
      "WALKING                  0        1         0      409                  20   \n",
      "WALKING_DOWNSTAIRS       0        0         0        7                 399   \n",
      "WALKING_UPSTAIRS         0        0         0        5                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             3  \n",
      "SITTING                           18  \n",
      "STANDING                          17  \n",
      "WALKING                           66  \n",
      "WALKING_DOWNSTAIRS                14  \n",
      "WALKING_UPSTAIRS                 466  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 256us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5602035771178105, 0.8812351822853088]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's perform worse than 64 layer with dropout 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.3 Use 2 LSTM Layers with Larger Dropout</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.1 LSTM Layer (64,32) with 2 layer of dropout 0.7</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_46 (LSTM)               (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 1.2737 - accuracy: 0.4884 - val_loss: 0.9074 - val_accuracy: 0.5938\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.8894 - accuracy: 0.6167 - val_loss: 0.7144 - val_accuracy: 0.6206\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 0.7967 - accuracy: 0.6294 - val_loss: 0.7580 - val_accuracy: 0.6237\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.7435 - accuracy: 0.6506 - val_loss: 0.7531 - val_accuracy: 0.6216\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.7146 - accuracy: 0.6518 - val_loss: 0.7442 - val_accuracy: 0.6315\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.7182 - accuracy: 0.6578 - val_loss: 0.7171 - val_accuracy: 0.6328\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.7103 - accuracy: 0.6644 - val_loss: 0.8312 - val_accuracy: 0.6189\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 0.6082 - accuracy: 0.7271 - val_loss: 0.5815 - val_accuracy: 0.7472\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.5212 - accuracy: 0.7779 - val_loss: 0.6235 - val_accuracy: 0.7482\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.4809 - accuracy: 0.7831 - val_loss: 0.4557 - val_accuracy: 0.7560\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.4502 - accuracy: 0.7949 - val_loss: 0.5220 - val_accuracy: 0.7486\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.4417 - accuracy: 0.8214 - val_loss: 0.4750 - val_accuracy: 0.8195\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.3882 - accuracy: 0.8807 - val_loss: 0.6525 - val_accuracy: 0.8300\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.3461 - accuracy: 0.9051 - val_loss: 0.3229 - val_accuracy: 0.8856\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.2932 - accuracy: 0.9212 - val_loss: 0.3832 - val_accuracy: 0.8873\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.2834 - accuracy: 0.9229 - val_loss: 0.4894 - val_accuracy: 0.8565\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: 0.2440 - accuracy: 0.9328 - val_loss: 0.3598 - val_accuracy: 0.9040\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2287 - accuracy: 0.9357 - val_loss: 0.2449 - val_accuracy: 0.9070\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.2432 - accuracy: 0.9314 - val_loss: 0.2899 - val_accuracy: 0.9199\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2307 - accuracy: 0.9343 - val_loss: 0.3551 - val_accuracy: 0.8948\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.2071 - accuracy: 0.9377 - val_loss: 0.3508 - val_accuracy: 0.9145\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.2145 - accuracy: 0.9353 - val_loss: 0.7906 - val_accuracy: 0.8666\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.2291 - accuracy: 0.9347 - val_loss: 0.3717 - val_accuracy: 0.9080\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 0.1955 - accuracy: 0.9402 - val_loss: 0.3518 - val_accuracy: 0.9182\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.2144 - accuracy: 0.9388 - val_loss: 0.4186 - val_accuracy: 0.9155\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2106 - accuracy: 0.9389 - val_loss: 0.2988 - val_accuracy: 0.9165\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1955 - accuracy: 0.9395 - val_loss: 0.3549 - val_accuracy: 0.9046\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: nan - accuracy: 0.3413 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63c6b10b8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                WALKING\n",
      "True                       \n",
      "LAYING                  537\n",
      "SITTING                 491\n",
      "STANDING                532\n",
      "WALKING                 496\n",
      "WALKING_DOWNSTAIRS      420\n",
      "WALKING_UPSTAIRS        471\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 0.16830675303936005]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's performance is worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.2 LSTM Layer (64,32) with 2 layer dropout 0.6</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 1.2568 - accuracy: 0.4778 - val_loss: 1.2977 - val_accuracy: 0.4462\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.8864 - accuracy: 0.6138 - val_loss: 0.8237 - val_accuracy: 0.6179\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.7344 - accuracy: 0.6719 - val_loss: 0.7058 - val_accuracy: 0.6804\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.6797 - accuracy: 0.7223 - val_loss: 0.6778 - val_accuracy: 0.7411\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.5348 - accuracy: 0.8092 - val_loss: 0.4354 - val_accuracy: 0.8537\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.3872 - accuracy: 0.8938 - val_loss: 0.4438 - val_accuracy: 0.8799\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.3565 - accuracy: 0.9079 - val_loss: 0.4188 - val_accuracy: 0.8823\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2932 - accuracy: 0.9203 - val_loss: 0.4461 - val_accuracy: 0.8850\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2624 - accuracy: 0.9271 - val_loss: 0.4734 - val_accuracy: 0.8894\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2479 - accuracy: 0.9272 - val_loss: 0.3673 - val_accuracy: 0.9023\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.2425 - accuracy: 0.9328 - val_loss: 0.4653 - val_accuracy: 0.8839\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2103 - accuracy: 0.9389 - val_loss: 0.3446 - val_accuracy: 0.9030\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1988 - accuracy: 0.9399 - val_loss: 0.3912 - val_accuracy: 0.9148\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1747 - accuracy: 0.9414 - val_loss: 0.5197 - val_accuracy: 0.8921\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1786 - accuracy: 0.9455 - val_loss: 0.6204 - val_accuracy: 0.8945\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1747 - accuracy: 0.9426 - val_loss: 0.3647 - val_accuracy: 0.9087\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1764 - accuracy: 0.9414 - val_loss: 0.7391 - val_accuracy: 0.8799\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1691 - accuracy: 0.9440 - val_loss: 0.3439 - val_accuracy: 0.9053\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1668 - accuracy: 0.9487 - val_loss: 0.4053 - val_accuracy: 0.9040\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1707 - accuracy: 0.9430 - val_loss: 0.5533 - val_accuracy: 0.8904\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1765 - accuracy: 0.9457 - val_loss: 0.4594 - val_accuracy: 0.9077\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2275 - accuracy: 0.9396 - val_loss: 0.4258 - val_accuracy: 0.9169\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1920 - accuracy: 0.9434 - val_loss: 0.4475 - val_accuracy: 0.9077\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1931 - accuracy: 0.9445 - val_loss: 0.6805 - val_accuracy: 0.8799\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.1535 - accuracy: 0.9461 - val_loss: 0.4987 - val_accuracy: 0.9006\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: nan - accuracy: 0.6254 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63d0cecf8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                WALKING\n",
      "True                       \n",
      "LAYING                  537\n",
      "SITTING                 491\n",
      "STANDING                532\n",
      "WALKING                 496\n",
      "WALKING_DOWNSTAIRS      420\n",
      "WALKING_UPSTAIRS        471\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 0.16830675303936005]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's performance is worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.3 LSTM Layer (64,32) with 2 layer dropout 0.5</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_50 (LSTM)               (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 1.0873 - accuracy: 0.5563 - val_loss: 0.7762 - val_accuracy: 0.7038\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.6862 - accuracy: 0.7337 - val_loss: 0.5855 - val_accuracy: 0.7299\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 118s 16ms/step - loss: 0.5282 - accuracy: 0.7763 - val_loss: 0.5286 - val_accuracy: 0.7615\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.4156 - accuracy: 0.8392 - val_loss: 0.4071 - val_accuracy: 0.8819\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.2848 - accuracy: 0.9139 - val_loss: 0.4556 - val_accuracy: 0.8755\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2346 - accuracy: 0.9327 - val_loss: 0.5155 - val_accuracy: 0.8731\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 0.2368 - accuracy: 0.9323 - val_loss: 0.4285 - val_accuracy: 0.8772\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.2111 - accuracy: 0.9358 - val_loss: 0.3157 - val_accuracy: 0.9057\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1866 - accuracy: 0.9404 - val_loss: 0.4269 - val_accuracy: 0.9019\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1835 - accuracy: 0.9389 - val_loss: 0.2840 - val_accuracy: 0.9108\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1625 - accuracy: 0.9470 - val_loss: 0.3311 - val_accuracy: 0.9077\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1528 - accuracy: 0.9460 - val_loss: 0.4299 - val_accuracy: 0.9145\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1541 - accuracy: 0.9434 - val_loss: 0.3474 - val_accuracy: 0.9199\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1506 - accuracy: 0.9464 - val_loss: 0.4714 - val_accuracy: 0.8968\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1506 - accuracy: 0.9482 - val_loss: 0.4906 - val_accuracy: 0.9104\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1481 - accuracy: 0.9486 - val_loss: 0.5460 - val_accuracy: 0.9023\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1604 - accuracy: 0.9490 - val_loss: 0.4505 - val_accuracy: 0.9057\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1389 - accuracy: 0.9510 - val_loss: 0.5048 - val_accuracy: 0.9036\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.1574 - accuracy: 0.9479 - val_loss: 0.6674 - val_accuracy: 0.8880\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1591 - accuracy: 0.9509 - val_loss: 0.5377 - val_accuracy: 0.9118\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1516 - accuracy: 0.9474 - val_loss: 0.3849 - val_accuracy: 0.9030\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1376 - accuracy: 0.9524 - val_loss: 0.9215 - val_accuracy: 0.8877\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1471 - accuracy: 0.9508 - val_loss: 0.5519 - val_accuracy: 0.9074\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1971 - accuracy: 0.9373 - val_loss: 0.6929 - val_accuracy: 0.8823\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1533 - accuracy: 0.9482 - val_loss: 0.6994 - val_accuracy: 0.8867\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 123s 17ms/step - loss: 0.1517 - accuracy: 0.9510 - val_loss: 0.4023 - val_accuracy: 0.8948\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1306 - accuracy: 0.9523 - val_loss: 0.4267 - val_accuracy: 0.9036\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1561 - accuracy: 0.9476 - val_loss: 0.5926 - val_accuracy: 0.9114\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1539 - accuracy: 0.9452 - val_loss: 0.5725 - val_accuracy: 0.9030\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.1292 - accuracy: 0.9533 - val_loss: 0.6457 - val_accuracy: 0.9002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63f20dd30>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        27        0                   0   \n",
      "SITTING                  0      397        91        0                   0   \n",
      "STANDING                 0       92       440        0                   0   \n",
      "WALKING                  0        1         1      458                  28   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 410   \n",
      "WALKING_UPSTAIRS         1        0         6       16                  10   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            3  \n",
      "STANDING                           0  \n",
      "WALKING                            8  \n",
      "WALKING_DOWNSTAIRS                 9  \n",
      "WALKING_UPSTAIRS                 438  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6456601167650766, 0.900237500667572]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's performance is better than 0.7 and 0.6 but loss is considerably high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.4 LSTM Layer (64,32) with 1 layer of dropout 0.7</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.5))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 1.2252 - accuracy: 0.4883 - val_loss: 0.9514 - val_accuracy: 0.5755\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.8989 - accuracy: 0.6023 - val_loss: 0.7508 - val_accuracy: 0.6498\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.7873 - accuracy: 0.6359 - val_loss: 0.7832 - val_accuracy: 0.6159\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.7230 - accuracy: 0.6726 - val_loss: 0.8069 - val_accuracy: 0.5959\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.6513 - accuracy: 0.6876 - val_loss: 0.7456 - val_accuracy: 0.6227\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.5906 - accuracy: 0.7155 - val_loss: 0.6538 - val_accuracy: 0.7469\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.5490 - accuracy: 0.7606 - val_loss: 0.5527 - val_accuracy: 0.7784\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.5179 - accuracy: 0.7835 - val_loss: 0.5049 - val_accuracy: 0.7720\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.4791 - accuracy: 0.8198 - val_loss: 0.5555 - val_accuracy: 0.8599\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.4130 - accuracy: 0.8700 - val_loss: 0.4166 - val_accuracy: 0.8751\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.3465 - accuracy: 0.9037 - val_loss: 0.3210 - val_accuracy: 0.8965\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2978 - accuracy: 0.9174 - val_loss: 0.3080 - val_accuracy: 0.9067\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2804 - accuracy: 0.9202 - val_loss: 0.3070 - val_accuracy: 0.9145\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2638 - accuracy: 0.9248 - val_loss: 0.3665 - val_accuracy: 0.9057\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.2558 - accuracy: 0.9266 - val_loss: 0.3212 - val_accuracy: 0.9125\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: 0.2393 - accuracy: 0.9369 - val_loss: 0.3172 - val_accuracy: 0.9148\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.2349 - accuracy: 0.9370 - val_loss: 0.3730 - val_accuracy: 0.9135\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2188 - accuracy: 0.9378 - val_loss: 0.3914 - val_accuracy: 0.9030\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.2022 - accuracy: 0.9384 - val_loss: 0.3416 - val_accuracy: 0.9274\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.1937 - accuracy: 0.9403 - val_loss: 0.3226 - val_accuracy: 0.9199\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2018 - accuracy: 0.9391 - val_loss: 0.3630 - val_accuracy: 0.9135\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: nan - accuracy: 0.5140 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: nan - accuracy: 0.1668 - val_loss: nan - val_accuracy: 0.1683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x640211cc0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                WALKING\n",
      "True                       \n",
      "LAYING                  537\n",
      "SITTING                 491\n",
      "STANDING                532\n",
      "WALKING                 496\n",
      "WALKING_DOWNSTAIRS      420\n",
      "WALKING_UPSTAIRS        471\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 0.16830675303936005]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's performance is worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.5 LSTM Layer (64,32) with 1 layer of dropout 0.6</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.5))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 118s 16ms/step - loss: 1.2553 - accuracy: 0.4732 - val_loss: 0.9856 - val_accuracy: 0.6434\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 108s 15ms/step - loss: 0.9545 - accuracy: 0.6049 - val_loss: 0.8514 - val_accuracy: 0.6244\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 136s 18ms/step - loss: 0.7894 - accuracy: 0.6738 - val_loss: 0.6679 - val_accuracy: 0.7408\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 0.6387 - accuracy: 0.7881 - val_loss: 0.5631 - val_accuracy: 0.7842\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.4644 - accuracy: 0.8754 - val_loss: 0.4742 - val_accuracy: 0.8548\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.3441 - accuracy: 0.9072 - val_loss: 0.3645 - val_accuracy: 0.8972\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.3192 - accuracy: 0.9155 - val_loss: 0.4117 - val_accuracy: 0.8904\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.3052 - accuracy: 0.9158 - val_loss: 0.4517 - val_accuracy: 0.8768\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2712 - accuracy: 0.9221 - val_loss: 0.3708 - val_accuracy: 0.9002\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.2295 - accuracy: 0.9372 - val_loss: 0.3945 - val_accuracy: 0.9108\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2267 - accuracy: 0.9385 - val_loss: 0.5272 - val_accuracy: 0.8935\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2112 - accuracy: 0.9363 - val_loss: 0.4001 - val_accuracy: 0.9060\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2116 - accuracy: 0.9414 - val_loss: 0.4747 - val_accuracy: 0.9023\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.2028 - accuracy: 0.9385 - val_loss: 0.4646 - val_accuracy: 0.9070\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1896 - accuracy: 0.9414 - val_loss: 0.4164 - val_accuracy: 0.9033\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1874 - accuracy: 0.9423 - val_loss: 0.2969 - val_accuracy: 0.9179\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.1810 - accuracy: 0.9399 - val_loss: 0.2758 - val_accuracy: 0.9182\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1782 - accuracy: 0.9425 - val_loss: 0.5199 - val_accuracy: 0.8941\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1690 - accuracy: 0.9476 - val_loss: 0.3118 - val_accuracy: 0.9213\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1558 - accuracy: 0.9433 - val_loss: 0.4242 - val_accuracy: 0.9155\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1561 - accuracy: 0.9505 - val_loss: 0.4087 - val_accuracy: 0.9026\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1585 - accuracy: 0.9467 - val_loss: 0.4679 - val_accuracy: 0.9019\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1696 - accuracy: 0.9452 - val_loss: 0.4305 - val_accuracy: 0.8999\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1605 - accuracy: 0.9479 - val_loss: 0.4813 - val_accuracy: 0.9019\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1505 - accuracy: 0.9480 - val_loss: 0.5688 - val_accuracy: 0.9016\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.1430 - accuracy: 0.9498 - val_loss: 0.5675 - val_accuracy: 0.8951\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1477 - accuracy: 0.9498 - val_loss: 0.6166 - val_accuracy: 0.8989\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1605 - accuracy: 0.9445 - val_loss: 0.3368 - val_accuracy: 0.9169\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1704 - accuracy: 0.9456 - val_loss: 0.3571 - val_accuracy: 0.9175\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1643 - accuracy: 0.9449 - val_loss: 0.5376 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63edc1a58>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 512        0        25        0                   0   \n",
      "SITTING                  2      400        87        0                   0   \n",
      "STANDING                 0       95       436        1                   0   \n",
      "WALKING                  0        0         0      450                   3   \n",
      "WALKING_DOWNSTAIRS       0        0         0        2                 414   \n",
      "WALKING_UPSTAIRS         1        0         0       11                   3   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                           43  \n",
      "WALKING_DOWNSTAIRS                 4  \n",
      "WALKING_UPSTAIRS                 456  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5375813010956876, 0.9053274393081665]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's performance is better but loss is higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.6 LSTM Layer (64,32) with 1 layer of dropout 0.5</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.5))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 1.1323 - accuracy: 0.5397 - val_loss: 0.8477 - val_accuracy: 0.6787\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.7404 - accuracy: 0.7203 - val_loss: 0.5979 - val_accuracy: 0.7699\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.5092 - accuracy: 0.8400 - val_loss: 1.2509 - val_accuracy: 0.6763\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.3954 - accuracy: 0.8917 - val_loss: 0.4537 - val_accuracy: 0.8300\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2696 - accuracy: 0.9217 - val_loss: 0.3626 - val_accuracy: 0.8887\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2443 - accuracy: 0.9300 - val_loss: 0.3439 - val_accuracy: 0.8975\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2122 - accuracy: 0.9350 - val_loss: 0.4547 - val_accuracy: 0.8996\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2518 - accuracy: 0.9225 - val_loss: 0.3921 - val_accuracy: 0.8982\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1827 - accuracy: 0.9440 - val_loss: 0.3997 - val_accuracy: 0.9019\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1704 - accuracy: 0.9460 - val_loss: 0.4512 - val_accuracy: 0.8782\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1747 - accuracy: 0.9406 - val_loss: 0.3169 - val_accuracy: 0.9080\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1636 - accuracy: 0.9459 - val_loss: 0.2829 - val_accuracy: 0.9162\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1427 - accuracy: 0.9514 - val_loss: 0.3661 - val_accuracy: 0.9013\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1546 - accuracy: 0.9475 - val_loss: 0.3250 - val_accuracy: 0.9128\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1498 - accuracy: 0.9518 - val_loss: 0.4040 - val_accuracy: 0.9046\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1360 - accuracy: 0.9525 - val_loss: 0.3080 - val_accuracy: 0.9087\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1641 - accuracy: 0.9431 - val_loss: 0.3339 - val_accuracy: 0.9189\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1443 - accuracy: 0.9497 - val_loss: 0.3439 - val_accuracy: 0.9084\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1435 - accuracy: 0.9494 - val_loss: 0.2949 - val_accuracy: 0.9104\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1318 - accuracy: 0.9543 - val_loss: 0.4108 - val_accuracy: 0.9074\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1448 - accuracy: 0.9509 - val_loss: 0.3502 - val_accuracy: 0.9135\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1454 - accuracy: 0.9495 - val_loss: 0.3810 - val_accuracy: 0.9101\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1220 - accuracy: 0.9547 - val_loss: 0.4707 - val_accuracy: 0.9040\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1434 - accuracy: 0.9487 - val_loss: 0.4171 - val_accuracy: 0.9087\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1398 - accuracy: 0.9506 - val_loss: 0.3381 - val_accuracy: 0.9179\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1377 - accuracy: 0.9504 - val_loss: 0.3495 - val_accuracy: 0.9114\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1352 - accuracy: 0.9512 - val_loss: 0.3892 - val_accuracy: 0.9175\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1536 - accuracy: 0.9480 - val_loss: 0.5848 - val_accuracy: 0.8985\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.1492 - accuracy: 0.9535 - val_loss: 0.4154 - val_accuracy: 0.9135\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1280 - accuracy: 0.9525 - val_loss: 0.3805 - val_accuracy: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64262e940>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        25        0                   0   \n",
      "SITTING                  3      416        68        0                   2   \n",
      "STANDING                 0       96       434        1                   0   \n",
      "WALKING                  0        0         2      473                  20   \n",
      "WALKING_DOWNSTAIRS       0        0         0        4                 413   \n",
      "WALKING_UPSTAIRS         0        1         6       16                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             2  \n",
      "SITTING                            2  \n",
      "STANDING                           1  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 3  \n",
      "WALKING_UPSTAIRS                 448  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3804781971405892, 0.9141499996185303]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's perform much better compared to 0.6 and 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.7 LSTM Layer (64,16) with dropout 0.5</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 24,230\n",
      "Trainable params: 24,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: 1.2980 - accuracy: 0.5016 - val_loss: 1.0061 - val_accuracy: 0.5796\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.9582 - accuracy: 0.6060 - val_loss: 0.8328 - val_accuracy: 0.6495\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.8071 - accuracy: 0.7008 - val_loss: 0.6999 - val_accuracy: 0.7710\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.6449 - accuracy: 0.7953 - val_loss: 0.5793 - val_accuracy: 0.8297\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.5014 - accuracy: 0.8687 - val_loss: 0.5518 - val_accuracy: 0.8422\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.4958 - accuracy: 0.8734 - val_loss: 0.3736 - val_accuracy: 0.8860\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.3628 - accuracy: 0.9060 - val_loss: 0.4399 - val_accuracy: 0.8860\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.3272 - accuracy: 0.9119 - val_loss: 0.3274 - val_accuracy: 0.9030\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2879 - accuracy: 0.9218 - val_loss: 0.3329 - val_accuracy: 0.9009\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2658 - accuracy: 0.9252 - val_loss: 0.6884 - val_accuracy: 0.8347\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.2757 - accuracy: 0.9193 - val_loss: 0.4459 - val_accuracy: 0.8955\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2671 - accuracy: 0.9245 - val_loss: 0.3746 - val_accuracy: 0.9070\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.2660 - accuracy: 0.9229 - val_loss: 0.3872 - val_accuracy: 0.9036\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.2746 - accuracy: 0.9197 - val_loss: 0.3580 - val_accuracy: 0.9091\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2464 - accuracy: 0.9225 - val_loss: 0.4930 - val_accuracy: 0.8975\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2147 - accuracy: 0.9320 - val_loss: 0.4268 - val_accuracy: 0.9063\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.2211 - accuracy: 0.9260 - val_loss: 0.4903 - val_accuracy: 0.8999\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.2274 - accuracy: 0.9261 - val_loss: 0.4916 - val_accuracy: 0.9063\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 0.2101 - accuracy: 0.9335 - val_loss: 0.5254 - val_accuracy: 0.9013\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2397 - accuracy: 0.9218 - val_loss: 0.4428 - val_accuracy: 0.9186\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.2112 - accuracy: 0.9241 - val_loss: 0.4918 - val_accuracy: 0.9023\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.2058 - accuracy: 0.9283 - val_loss: 0.4324 - val_accuracy: 0.9175\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2068 - accuracy: 0.9316 - val_loss: 0.5082 - val_accuracy: 0.8951\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2010 - accuracy: 0.9325 - val_loss: 0.4982 - val_accuracy: 0.9026\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.2106 - accuracy: 0.9316 - val_loss: 0.6370 - val_accuracy: 0.8921\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 0.2256 - accuracy: 0.9276 - val_loss: 0.5423 - val_accuracy: 0.9023\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.2045 - accuracy: 0.9340 - val_loss: 0.5803 - val_accuracy: 0.9141\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 0.2197 - accuracy: 0.9323 - val_loss: 0.5890 - val_accuracy: 0.9050\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.1964 - accuracy: 0.9357 - val_loss: 0.5434 - val_accuracy: 0.9091\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1971 - accuracy: 0.9308 - val_loss: 0.5415 - val_accuracy: 0.9057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x644516ef0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         3        0                   0   \n",
      "SITTING                  5      425        57        2                   0   \n",
      "STANDING                 0      101       430        0                   0   \n",
      "WALKING                  0        0         0      444                  34   \n",
      "WALKING_DOWNSTAIRS       0        0         0        5                 401   \n",
      "WALKING_UPSTAIRS         0        0         0        0                  12   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            24  \n",
      "SITTING                            2  \n",
      "STANDING                           1  \n",
      "WALKING                           18  \n",
      "WALKING_DOWNSTAIRS                14  \n",
      "WALKING_UPSTAIRS                 459  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5414807511955393, 0.9056667685508728]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's performance is good but loss is high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.8 LSTM Layer (32,16) with dropout 0.5</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_62 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 8,614\n",
      "Trainable params: 8,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 108s 15ms/step - loss: 1.3059 - accuracy: 0.4993 - val_loss: 1.0121 - val_accuracy: 0.5724\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 113s 15ms/step - loss: 0.9606 - accuracy: 0.5797 - val_loss: 0.7977 - val_accuracy: 0.6081\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.8199 - accuracy: 0.6274 - val_loss: 0.7922 - val_accuracy: 0.5938\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.7544 - accuracy: 0.6387 - val_loss: 0.7379 - val_accuracy: 0.6179\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 111s 15ms/step - loss: 0.7201 - accuracy: 0.6538 - val_loss: 0.7295 - val_accuracy: 0.6315\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.7087 - accuracy: 0.6568 - val_loss: 0.7252 - val_accuracy: 0.6247\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 92s 13ms/step - loss: 0.6802 - accuracy: 0.6673 - val_loss: 0.7158 - val_accuracy: 0.6172\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.6422 - accuracy: 0.6827 - val_loss: 0.6055 - val_accuracy: 0.6335\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.6010 - accuracy: 0.6967 - val_loss: 0.5963 - val_accuracy: 0.6345\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.5590 - accuracy: 0.7346 - val_loss: 0.5663 - val_accuracy: 0.7455\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.5296 - accuracy: 0.7776 - val_loss: 0.5300 - val_accuracy: 0.7645\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.4499 - accuracy: 0.8449 - val_loss: 0.4595 - val_accuracy: 0.8690\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.3973 - accuracy: 0.8825 - val_loss: 0.3912 - val_accuracy: 0.8748\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.3332 - accuracy: 0.8976 - val_loss: 0.3851 - val_accuracy: 0.8928\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.3229 - accuracy: 0.9115 - val_loss: 0.4235 - val_accuracy: 0.8772\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.2927 - accuracy: 0.9166 - val_loss: 0.3071 - val_accuracy: 0.9013\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.2774 - accuracy: 0.9210 - val_loss: 0.4124 - val_accuracy: 0.9019\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2632 - accuracy: 0.9267 - val_loss: 0.3328 - val_accuracy: 0.9053\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.2567 - accuracy: 0.9286 - val_loss: 0.3363 - val_accuracy: 0.8921\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 0.2283 - accuracy: 0.9346 - val_loss: 0.3214 - val_accuracy: 0.9077\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 70s 9ms/step - loss: 0.2282 - accuracy: 0.9357 - val_loss: 0.4113 - val_accuracy: 0.8965\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2258 - accuracy: 0.9332 - val_loss: 0.3970 - val_accuracy: 0.8965\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2020 - accuracy: 0.9400 - val_loss: 0.3651 - val_accuracy: 0.9077\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2156 - accuracy: 0.9372 - val_loss: 0.2834 - val_accuracy: 0.9199\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.2100 - accuracy: 0.9369 - val_loss: 0.2916 - val_accuracy: 0.9145\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 70s 9ms/step - loss: 0.2071 - accuracy: 0.9369 - val_loss: 0.3984 - val_accuracy: 0.9053\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.2109 - accuracy: 0.9388 - val_loss: 0.3134 - val_accuracy: 0.9172\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 0.2009 - accuracy: 0.9374 - val_loss: 0.3572 - val_accuracy: 0.9199\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.2002 - accuracy: 0.9377 - val_loss: 0.3658 - val_accuracy: 0.9128\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.2017 - accuracy: 0.9395 - val_loss: 0.3589 - val_accuracy: 0.9226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6456d7a20>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 536        0         1        0                   0   \n",
      "SITTING                  1      414        71        2                   1   \n",
      "STANDING                 0       80       445        7                   0   \n",
      "WALKING                  0        0         0      458                   9   \n",
      "WALKING_DOWNSTAIRS       0        6         0        1                 403   \n",
      "WALKING_UPSTAIRS         0        1         0        4                   3   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                           29  \n",
      "WALKING_DOWNSTAIRS                10  \n",
      "WALKING_UPSTAIRS                 463  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3589311393391746, 0.922633171081543]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's performance is best till now, I got 92.26% accuracy and loss 0.3589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3.9 LSTM Layer (32,8) with dropout 0.5</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 8)                 1312      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 6,742\n",
      "Trainable params: 6,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 1.4856 - accuracy: 0.4123 - val_loss: 1.3371 - val_accuracy: 0.4608\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 1.2285 - accuracy: 0.5116 - val_loss: 1.0945 - val_accuracy: 0.5270\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 1.0665 - accuracy: 0.5305 - val_loss: 0.9436 - val_accuracy: 0.5541\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.9660 - accuracy: 0.5257 - val_loss: 0.9440 - val_accuracy: 0.4880\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.9060 - accuracy: 0.5547 - val_loss: 0.8240 - val_accuracy: 0.5684\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.8786 - accuracy: 0.5654 - val_loss: 0.7971 - val_accuracy: 0.6529\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.8483 - accuracy: 0.5914 - val_loss: 0.8113 - val_accuracy: 0.6586\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.8286 - accuracy: 0.6151 - val_loss: 0.8513 - val_accuracy: 0.6071\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.8480 - accuracy: 0.6223 - val_loss: 0.7308 - val_accuracy: 0.6508\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.7699 - accuracy: 0.6659 - val_loss: 0.6510 - val_accuracy: 0.7122\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.7407 - accuracy: 0.6878 - val_loss: 0.6161 - val_accuracy: 0.7282\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.7204 - accuracy: 0.7065 - val_loss: 0.6398 - val_accuracy: 0.7489\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.6857 - accuracy: 0.7171 - val_loss: 0.5320 - val_accuracy: 0.7818\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.6436 - accuracy: 0.7297 - val_loss: 0.5111 - val_accuracy: 0.7374\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.6151 - accuracy: 0.7432 - val_loss: 0.4787 - val_accuracy: 0.7296\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.6339 - accuracy: 0.7444 - val_loss: 0.4256 - val_accuracy: 0.7642\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.5582 - accuracy: 0.7655 - val_loss: 0.4290 - val_accuracy: 0.7560\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.5327 - accuracy: 0.7703 - val_loss: 0.4810 - val_accuracy: 0.7669\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.5647 - accuracy: 0.7677 - val_loss: 0.4285 - val_accuracy: 0.7516\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.5090 - accuracy: 0.7817 - val_loss: 0.3965 - val_accuracy: 0.7401\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.5086 - accuracy: 0.7835 - val_loss: 0.4745 - val_accuracy: 0.7418\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.4800 - accuracy: 0.7829 - val_loss: 0.4516 - val_accuracy: 0.7282\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.4852 - accuracy: 0.7777 - val_loss: 0.4051 - val_accuracy: 0.7533\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.4614 - accuracy: 0.7845 - val_loss: 0.3709 - val_accuracy: 0.7540\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.4826 - accuracy: 0.7795 - val_loss: 1.3639 - val_accuracy: 0.6037\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.5301 - accuracy: 0.7686 - val_loss: 0.8841 - val_accuracy: 0.6529\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.4808 - accuracy: 0.7758 - val_loss: 0.3784 - val_accuracy: 0.7472\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.4476 - accuracy: 0.7924 - val_loss: 0.4192 - val_accuracy: 0.7520\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.4208 - accuracy: 0.8067 - val_loss: 0.3983 - val_accuracy: 0.7496\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.4232 - accuracy: 0.7926 - val_loss: 0.3762 - val_accuracy: 0.7540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64672ce10>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 534        0         0        0                   0   \n",
      "SITTING                  0      420        61        0                   0   \n",
      "STANDING                 0      122       405        0                   0   \n",
      "WALKING                  0        0         0        0                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         0        4                 397   \n",
      "WALKING_UPSTAIRS         0        5         0        0                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             3  \n",
      "SITTING                           10  \n",
      "STANDING                           5  \n",
      "WALKING                          496  \n",
      "WALKING_DOWNSTAIRS                19  \n",
      "WALKING_UPSTAIRS                 466  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 953us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3761567989555303, 0.7539871335029602]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance degraded for this combination of LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.0 Assignment feedback to improve accuracy > 94% </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.1 Increase dropout on the best LSTM combination</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 8,614\n",
      "Trainable params: 8,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mayankgupta/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/mayankgupta/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 1.3771 - accuracy: 0.4679 - val_loss: 1.2075 - val_accuracy: 0.5063\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 1.0661 - accuracy: 0.5615 - val_loss: 0.9215 - val_accuracy: 0.6546\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.9246 - accuracy: 0.6035 - val_loss: 0.7882 - val_accuracy: 0.6474\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.8082 - accuracy: 0.6484 - val_loss: 0.9662 - val_accuracy: 0.6223\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.7176 - accuracy: 0.7084 - val_loss: 0.7233 - val_accuracy: 0.6702\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.6610 - accuracy: 0.7329 - val_loss: 0.6340 - val_accuracy: 0.7268\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.5957 - accuracy: 0.7606 - val_loss: 0.4884 - val_accuracy: 0.7458\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.5444 - accuracy: 0.7705 - val_loss: 0.4884 - val_accuracy: 0.7547\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.5301 - accuracy: 0.7749 - val_loss: 0.5527 - val_accuracy: 0.7448\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4985 - accuracy: 0.7761 - val_loss: 0.5010 - val_accuracy: 0.7489\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.4811 - accuracy: 0.7811 - val_loss: 0.5013 - val_accuracy: 0.7706\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4723 - accuracy: 0.7758 - val_loss: 0.5427 - val_accuracy: 0.7384\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4699 - accuracy: 0.7801 - val_loss: 0.5415 - val_accuracy: 0.7638\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4475 - accuracy: 0.7879 - val_loss: 0.5366 - val_accuracy: 0.7564\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4817 - accuracy: 0.7795 - val_loss: 0.9002 - val_accuracy: 0.6841\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4505 - accuracy: 0.7894 - val_loss: 0.4372 - val_accuracy: 0.7798\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4303 - accuracy: 0.7878 - val_loss: 0.4430 - val_accuracy: 0.7845\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4273 - accuracy: 0.7950 - val_loss: 0.4931 - val_accuracy: 0.7672\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.4387 - accuracy: 0.7996 - val_loss: 0.4052 - val_accuracy: 0.7927\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4401 - accuracy: 0.8062 - val_loss: 0.4650 - val_accuracy: 0.7774\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4293 - accuracy: 0.8244 - val_loss: 0.5555 - val_accuracy: 0.7587\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.3975 - accuracy: 0.8384 - val_loss: 0.4290 - val_accuracy: 0.7665\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.3760 - accuracy: 0.8474 - val_loss: 0.4030 - val_accuracy: 0.8836\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.3758 - accuracy: 0.8453 - val_loss: 0.4144 - val_accuracy: 0.9057\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.3429 - accuracy: 0.8659 - val_loss: 0.4352 - val_accuracy: 0.8948\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.3329 - accuracy: 0.8802 - val_loss: 0.4077 - val_accuracy: 0.8914\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.3310 - accuracy: 0.8977 - val_loss: 0.3974 - val_accuracy: 0.8948\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.3205 - accuracy: 0.9048 - val_loss: 0.3721 - val_accuracy: 0.8897\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.2805 - accuracy: 0.9168 - val_loss: 0.4258 - val_accuracy: 0.8833\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.2897 - accuracy: 0.9117 - val_loss: 0.3616 - val_accuracy: 0.9101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x629ebef60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         2        0                   0   \n",
      "SITTING                  0      404        87        0                   0   \n",
      "STANDING                 0       81       450        1                   0   \n",
      "WALKING                  0        0         0      450                  44   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 414   \n",
      "WALKING_UPSTAIRS         1        0        10        0                   6   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            25  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                 6  \n",
      "WALKING_UPSTAIRS                 454  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 402us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36157595883878874, 0.9100780487060547]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.2 Decrease dropout on the best LSTM combination</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize the LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 8,614\n",
      "Trainable params: 8,614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.4))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.2955 - accuracy: 0.5092 - val_loss: 0.9788 - val_accuracy: 0.5667\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.9335 - accuracy: 0.6260 - val_loss: 0.8553 - val_accuracy: 0.5850\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.7509 - accuracy: 0.6903 - val_loss: 0.6851 - val_accuracy: 0.6875\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.6576 - accuracy: 0.7371 - val_loss: 0.6529 - val_accuracy: 0.7153\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.5653 - accuracy: 0.7776 - val_loss: 0.5315 - val_accuracy: 0.7598\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4963 - accuracy: 0.7875 - val_loss: 0.5693 - val_accuracy: 0.7397\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4593 - accuracy: 0.8021 - val_loss: 0.8562 - val_accuracy: 0.6997\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4336 - accuracy: 0.8022 - val_loss: 0.4901 - val_accuracy: 0.7733\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.4291 - accuracy: 0.8105 - val_loss: 0.4846 - val_accuracy: 0.8344\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.3871 - accuracy: 0.8746 - val_loss: 0.4090 - val_accuracy: 0.8626\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.3232 - accuracy: 0.9104 - val_loss: 0.3683 - val_accuracy: 0.8884\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.2601 - accuracy: 0.9312 - val_loss: 0.4261 - val_accuracy: 0.8789\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.2371 - accuracy: 0.9312 - val_loss: 0.3696 - val_accuracy: 0.8955\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.2219 - accuracy: 0.9354 - val_loss: 0.3854 - val_accuracy: 0.8897\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.2124 - accuracy: 0.9388 - val_loss: 0.3734 - val_accuracy: 0.8890\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1963 - accuracy: 0.9403 - val_loss: 0.4284 - val_accuracy: 0.8887\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1849 - accuracy: 0.9396 - val_loss: 0.3498 - val_accuracy: 0.9016\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1981 - accuracy: 0.9415 - val_loss: 0.4388 - val_accuracy: 0.8924\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1978 - accuracy: 0.9408 - val_loss: 0.4307 - val_accuracy: 0.8911\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1884 - accuracy: 0.9377 - val_loss: 0.4191 - val_accuracy: 0.8948\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1669 - accuracy: 0.9444 - val_loss: 0.5406 - val_accuracy: 0.8901\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1731 - accuracy: 0.9442 - val_loss: 0.4263 - val_accuracy: 0.8921\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1697 - accuracy: 0.9459 - val_loss: 0.4441 - val_accuracy: 0.8904\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1615 - accuracy: 0.9474 - val_loss: 0.4375 - val_accuracy: 0.8955\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1651 - accuracy: 0.9448 - val_loss: 0.6645 - val_accuracy: 0.8826\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1563 - accuracy: 0.9475 - val_loss: 0.6143 - val_accuracy: 0.8890\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1582 - accuracy: 0.9489 - val_loss: 0.5653 - val_accuracy: 0.8958\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1520 - accuracy: 0.9465 - val_loss: 0.3868 - val_accuracy: 0.9111\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1610 - accuracy: 0.9465 - val_loss: 0.4674 - val_accuracy: 0.9033\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1460 - accuracy: 0.9489 - val_loss: 0.3913 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x62b400e10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  4      387        78        0                   4   \n",
      "STANDING                 0       98       432        0                   0   \n",
      "WALKING                  0        0         0      448                  10   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 413   \n",
      "WALKING_UPSTAIRS         0        0         0        7                   9   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                           18  \n",
      "STANDING                           2  \n",
      "WALKING                           38  \n",
      "WALKING_DOWNSTAIRS                 7  \n",
      "WALKING_UPSTAIRS                 455  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 397us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39125852214684165, 0.9066847562789917]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.3 Increase layer size to 128 and lesser dropout</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update LSTM layers\n",
    "n_hidden_1 = 128\n",
    "# n_hidden_2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 71,942\n",
      "Trainable params: 71,686\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/51763983/error-when-checking-target-expected-dense-1-to-have-3-dimensions-but-got-array\n",
    "# https://github.com/keras-team/keras/issues/7403\n",
    "# 1. You need to set return_sequences=True from first LSTM\n",
    "# 2. You need to set return_sequences=True from second LSTM\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1, input_shape=(timesteps, input_dim)))#, return_sequences=True\n",
    "# Adding BatchNormalization\n",
    "model.add(BatchNormalization())\n",
    "# Adding a dropout layer\n",
    "# model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "# model.add(LSTM(n_hidden_2 , return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.9291 - accuracy: 0.5952 - val_loss: 0.7638 - val_accuracy: 0.6359\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.6998 - accuracy: 0.6602 - val_loss: 0.6965 - val_accuracy: 0.6481\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.5196 - accuracy: 0.7916 - val_loss: 0.3441 - val_accuracy: 0.8907\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2674 - accuracy: 0.9101 - val_loss: 0.3433 - val_accuracy: 0.8989\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1985 - accuracy: 0.9293 - val_loss: 0.3900 - val_accuracy: 0.8772\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1990 - accuracy: 0.9279 - val_loss: 0.3218 - val_accuracy: 0.9121\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1790 - accuracy: 0.9362 - val_loss: 0.2864 - val_accuracy: 0.9108\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1543 - accuracy: 0.9412 - val_loss: 0.2592 - val_accuracy: 0.9199\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1592 - accuracy: 0.9404 - val_loss: 0.3458 - val_accuracy: 0.9158\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1445 - accuracy: 0.9436 - val_loss: 0.2678 - val_accuracy: 0.9199\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1397 - accuracy: 0.9395 - val_loss: 0.2976 - val_accuracy: 0.9155\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1523 - accuracy: 0.9392 - val_loss: 0.2769 - val_accuracy: 0.9070\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1375 - accuracy: 0.9415 - val_loss: 0.3131 - val_accuracy: 0.9087\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.1459 - accuracy: 0.9433 - val_loss: 0.3071 - val_accuracy: 0.9152\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1451 - accuracy: 0.9455 - val_loss: 0.3450 - val_accuracy: 0.9169\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1497 - accuracy: 0.9460 - val_loss: 0.3297 - val_accuracy: 0.9158\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1425 - accuracy: 0.9489 - val_loss: 0.3909 - val_accuracy: 0.9192\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1529 - accuracy: 0.9465 - val_loss: 0.3178 - val_accuracy: 0.9220\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1487 - accuracy: 0.9456 - val_loss: 0.3939 - val_accuracy: 0.9104\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1389 - accuracy: 0.9483 - val_loss: 0.3776 - val_accuracy: 0.9179\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1451 - accuracy: 0.9449 - val_loss: 0.3028 - val_accuracy: 0.9233\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1386 - accuracy: 0.9465 - val_loss: 0.3515 - val_accuracy: 0.9247\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2044 - accuracy: 0.9280 - val_loss: 0.3435 - val_accuracy: 0.9226\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1235 - accuracy: 0.9521 - val_loss: 0.3666 - val_accuracy: 0.9230\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1276 - accuracy: 0.9504 - val_loss: 0.3031 - val_accuracy: 0.9182\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1243 - accuracy: 0.9520 - val_loss: 0.3607 - val_accuracy: 0.9257\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1223 - accuracy: 0.9502 - val_loss: 0.3756 - val_accuracy: 0.9155\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1273 - accuracy: 0.9525 - val_loss: 0.3839 - val_accuracy: 0.9186\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1620 - accuracy: 0.9433 - val_loss: 0.2694 - val_accuracy: 0.9294\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1218 - accuracy: 0.9510 - val_loss: 0.3121 - val_accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x62db041d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      418        71        0                   0   \n",
      "STANDING                 0      101       431        0                   0   \n",
      "WALKING                  0        0         0      470                  24   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 417   \n",
      "WALKING_UPSTAIRS         0        1         0       13                   2   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 455  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 2s 542us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31214076887265046, 0.9256871342658997]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.4 Implement Divide and Conquer Technique</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citation: https://github.com/UdiBhaskar/Human-Activity-Recognition--Using-Deep-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, Y_labels are represented as numbers from 1 to 6 as their identifiers.  \n",
    "WALKING as 1  \n",
    "WALKING_UPSTAIRS as 2  \n",
    "WALKING_DOWNSTAIRS as 3  \n",
    "SITTING as 4  \n",
    "STANDING as 5  \n",
    "LAYING as 6    \n",
    "- in Data exploration section we observed that we can divide the data into dynamic and static type so divided walking, walking_upstairs and walking_downstairs into category 0 i.e Dynamic and sitting, standing and laying into category 1 i.e. static. \n",
    "- Will use 2 more classifiers separately for classifying classes of dynamic and static activities. so that model can learn differnt features for static and dynamic activities\n",
    "\n",
    "\n",
    "referred below paper  \n",
    "Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening ( https://www.mdpi.com/1424-8220/18/4/1055/pdf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20200212 Mayank Gupta I completly refactored the code provided in the above github repo, \n",
    "# I didn't follow the oops based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def dump_file(filename, mode, data):\n",
    "    '''\n",
    "    Save model on the disk\n",
    "    '''\n",
    "    pickle.dump(data, open(filename, mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_y_static_dynamic(subset):\n",
    "        \"\"\"\n",
    "        The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "        that represents a human activity. We return a binary representation of \n",
    "        every sample objective as a 6 bits vector using One Hot Encoding\n",
    "        (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "        \"\"\"\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "        y = _read_csv(filename)[0]\n",
    "        y[y<=3] = 0\n",
    "        y[y>3] = 1\n",
    "        return pd.get_dummies(y).as_matrix()\n",
    "    \n",
    "def load_data_static_dynamic():\n",
    "    '''\n",
    "    Load train, test data and scale the data as well\n",
    "    '''\n",
    "    X_train_2c, X_val_2c = load_signals('train'), load_signals('test')\n",
    "    Y_train_2c, Y_val_2c = load_y_static_dynamic('train'), load_y_static_dynamic('test')\n",
    "    \n",
    "    # fit and transform data\n",
    "    Scale = fit(X_train_2c)\n",
    "    dump_file('Scale_2class.p','wb', Scale)\n",
    "    X_train_2c = transform(X_train_2c, Scale)\n",
    "    X_val_2c = transform(X_val_2c, Scale)\n",
    "    \n",
    "    return X_train_2c, Y_train_2c, X_val_2c, Y_val_2c \n",
    "\n",
    "def transform(X, scale):\n",
    "    '''\n",
    "    Transform the data\n",
    "    '''\n",
    "    temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
    "    temp_X1 = scale.transform(temp_X1)\n",
    "    return temp_X1.reshape(X.shape)\n",
    "\n",
    "def fit(X):\n",
    "    '''\n",
    "    Fit data for scaling\n",
    "    '''\n",
    "    # remove overlaping\n",
    "    remove = int(X.shape[1] / 2)\n",
    "    temp_X = X[:, -remove:, :]\n",
    "    # flatten data\n",
    "    temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(temp_X)\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayankgupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "/Users/mayankgupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train_2c, Y_train_2c, X_val_2c,  Y_val_2c = load_data_static_dynamic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 2)\n",
      "(2947, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_2c.shape)\n",
    "print(Y_val_2c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.4.4.1 Model for classifying data into Static and Dynamic activities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /Users/mayankgupta/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                99250     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 103,352\n",
      "Trainable params: 103,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Clear previous session\n",
    "K.clear_session()\n",
    "# Add seed\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "# Start Session\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "K.set_session(sess)\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import math\n",
    "adam = keras.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 3s 448us/step - loss: 0.0371 - accuracy: 0.9869 - val_loss: 0.0202 - val_accuracy: 0.9949\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 3s 432us/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0404 - val_accuracy: 0.9881\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 3s 429us/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0480 - val_accuracy: 0.9834\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 3s 433us/step - loss: 8.4357e-06 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9834\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 3s 430us/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.1564 - val_accuracy: 0.9851\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 3s 432us/step - loss: 1.7301e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9871\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 3s 435us/step - loss: 1.0457e-04 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9810\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 3s 423us/step - loss: 1.5191e-05 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9871\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 3s 430us/step - loss: 3.3170e-06 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9871\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 3s 422us/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0903 - val_accuracy: 0.9891\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 3s 426us/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0193 - val_accuracy: 0.9963\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 3s 431us/step - loss: 2.6799e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9976\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 3s 426us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0103 - val_accuracy: 0.9976\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 3s 430us/step - loss: 9.5532e-06 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 3s 438us/step - loss: 1.2184e-06 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 4s 522us/step - loss: 2.4589e-05 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9983\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 3s 455us/step - loss: 7.1136e-06 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9983\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 3s 434us/step - loss: 9.7108e-07 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9983\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 3s 424us/step - loss: 2.4397e-07 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9983\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 3s 423us/step - loss: 1.7281e-07 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x633c85be0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(X_train_2c,Y_train_2c, epochs=20, batch_size=16,validation_data=(X_val_2c, Y_val_2c), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_accuracy 1.0 test_accuracy 0.9983033537864685\n"
     ]
    }
   ],
   "source": [
    "_,acc_val = model.evaluate(X_val_2c,Y_val_2c,verbose=0)\n",
    "_,acc_train = model.evaluate(X_train_2c,Y_train_2c,verbose=0)\n",
    "print('Train_accuracy',acc_train,'test_accuracy',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving model\n",
    "model.save('final_model_2class.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification of Static and Dynamic Activities is Perfect, We got 99.83% accuracy on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.4.2 Model for Classifying Static Activities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y_static(subset):\n",
    "        \"\"\"\n",
    "        The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "        that represents a human activity. We return a binary representation of \n",
    "        every sample objective as a 6 bits vector using One Hot Encoding\n",
    "        (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "        \"\"\"\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "        y = _read_csv(filename)[0]\n",
    "        y_subset = y>3\n",
    "        y = y[y_subset]\n",
    "        return pd.get_dummies(y).as_matrix(),y_subset\n",
    "    \n",
    "def load_data_static():\n",
    "    '''\n",
    "    Load train, test data and scale the data as well\n",
    "    '''\n",
    "    Y_train_s, y_train_sub = load_y_static('train')\n",
    "    Y_val_s, y_test_sub = load_y_static('test')\n",
    "    \n",
    "    X_train_s, X_val_s = load_signals('train'), load_signals('test')\n",
    "    X_train_s = X_train_s[y_train_sub]\n",
    "    X_val_s = X_val_s[y_test_sub]\n",
    "    \n",
    "    # fit and transform data\n",
    "    Scale = None\n",
    "    Scale = fit(X_train_s)\n",
    "    dump_file('Scale_static.p','wb', Scale)\n",
    "    X_train_s = transform(X_train_s, Scale)\n",
    "    X_val_s = transform(X_val_s, Scale)\n",
    "    \n",
    "    return X_train_s, Y_train_s, X_val_s, Y_val_s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayankgupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "X_train_s, Y_train_s, X_val_s,  Y_val_s = load_data_static()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape of train data (4067, 128, 9) Y shape (4067, 3)\n",
      "X Shape of val data (1560, 128, 9) Y shape (1560, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X Shape of train data',X_train_s.shape, 'Y shape', Y_train_s.shape)\n",
    "print('X Shape of val data',X_val_s.shape,'Y shape',Y_val_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model to distinguish Static Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 122, 64)           4096      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 120, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                38430     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 48,795\n",
      "Trainable params: 48,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Clear session\n",
    "K.clear_session()\n",
    "# Random seed\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "# Start session\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "K.set_session(sess)\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=7, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4067 samples, validate on 1560 samples\n",
      "Epoch 1/20\n",
      "4067/4067 [==============================] - 1s 356us/step - loss: 0.3909 - accuracy: 0.8645 - val_loss: 0.3511 - val_accuracy: 0.8756\n",
      "Epoch 2/20\n",
      "4067/4067 [==============================] - 1s 313us/step - loss: 0.2796 - accuracy: 0.9073 - val_loss: 0.3104 - val_accuracy: 0.8821\n",
      "Epoch 3/20\n",
      "4067/4067 [==============================] - 1s 318us/step - loss: 0.1880 - accuracy: 0.9230 - val_loss: 0.3504 - val_accuracy: 0.8737\n",
      "Epoch 4/20\n",
      "4067/4067 [==============================] - 1s 306us/step - loss: 0.1893 - accuracy: 0.9270 - val_loss: 0.4072 - val_accuracy: 0.8795\n",
      "Epoch 5/20\n",
      "4067/4067 [==============================] - 1s 314us/step - loss: 0.1932 - accuracy: 0.9272 - val_loss: 0.3510 - val_accuracy: 0.8942\n",
      "Epoch 6/20\n",
      "4067/4067 [==============================] - 1s 312us/step - loss: 0.1570 - accuracy: 0.9400 - val_loss: 0.2834 - val_accuracy: 0.9205\n",
      "Epoch 7/20\n",
      "4067/4067 [==============================] - 1s 321us/step - loss: 0.1536 - accuracy: 0.9417 - val_loss: 0.3581 - val_accuracy: 0.8923\n",
      "Epoch 8/20\n",
      "4067/4067 [==============================] - 1s 318us/step - loss: 0.1305 - accuracy: 0.9486 - val_loss: 0.3250 - val_accuracy: 0.9135\n",
      "Epoch 9/20\n",
      "4067/4067 [==============================] - 1s 309us/step - loss: 0.1279 - accuracy: 0.9508 - val_loss: 0.3133 - val_accuracy: 0.9224\n",
      "Epoch 10/20\n",
      "4067/4067 [==============================] - 1s 314us/step - loss: 0.1187 - accuracy: 0.9543 - val_loss: 0.3198 - val_accuracy: 0.8846\n",
      "Epoch 11/20\n",
      "4067/4067 [==============================] - 1s 309us/step - loss: 0.1281 - accuracy: 0.9511 - val_loss: 0.2427 - val_accuracy: 0.9038\n",
      "Epoch 12/20\n",
      "4067/4067 [==============================] - 1s 306us/step - loss: 0.2054 - accuracy: 0.9430 - val_loss: 0.2403 - val_accuracy: 0.9071\n",
      "Epoch 13/20\n",
      "4067/4067 [==============================] - 1s 313us/step - loss: 0.1181 - accuracy: 0.9498 - val_loss: 0.1966 - val_accuracy: 0.9397\n",
      "Epoch 14/20\n",
      "4067/4067 [==============================] - 1s 314us/step - loss: 0.1308 - accuracy: 0.9543 - val_loss: 0.1835 - val_accuracy: 0.9462\n",
      "Epoch 15/20\n",
      "4067/4067 [==============================] - 1s 317us/step - loss: 0.1231 - accuracy: 0.9609 - val_loss: 0.2575 - val_accuracy: 0.9288\n",
      "Epoch 16/20\n",
      "4067/4067 [==============================] - 1s 310us/step - loss: 0.1269 - accuracy: 0.9471 - val_loss: 0.2157 - val_accuracy: 0.9378\n",
      "Epoch 17/20\n",
      "4067/4067 [==============================] - 1s 312us/step - loss: 0.1078 - accuracy: 0.9570 - val_loss: 0.1923 - val_accuracy: 0.9391\n",
      "Epoch 18/20\n",
      "4067/4067 [==============================] - 1s 309us/step - loss: 0.1097 - accuracy: 0.9567 - val_loss: 0.2281 - val_accuracy: 0.9276\n",
      "Epoch 19/20\n",
      "4067/4067 [==============================] - 1s 315us/step - loss: 0.1035 - accuracy: 0.9570 - val_loss: 0.2457 - val_accuracy: 0.9160\n",
      "Epoch 20/20\n",
      "4067/4067 [==============================] - 1s 304us/step - loss: 0.0795 - accuracy: 0.9680 - val_loss: 0.2568 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6342bbdd8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "adam = keras.optimizers.Adam(lr=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(X_train_s,Y_train_s, epochs=20, batch_size=32,validation_data=(X_val_s, Y_val_s), verbose=1)\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_accuracy 0.9773789048194885 test_accuracy 0.9230769276618958\n"
     ]
    }
   ],
   "source": [
    "_,acc_val = model.evaluate(X_val_s, Y_val_s,verbose=0)\n",
    "_,acc_train = model.evaluate(X_train_s,Y_train_s,verbose=0)\n",
    "print('Train_accuracy',acc_train,'test_accuracy',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving model\n",
    "model.save('final_model_static.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear tf session\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple model gives us approx. 95% accuracy for classifying Static Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.4.3 Model for Classifying Dynamic Activities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y_dynamic(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    y_subset = y<=3\n",
    "    y = y[y_subset]\n",
    "    return pd.get_dummies(y).as_matrix(),y_subset\n",
    "    \n",
    "def load_data_dynamic():\n",
    "    '''\n",
    "    Load train, test data and scale the data as well\n",
    "    '''\n",
    "    Y_train_d, y_train_sub = load_y_dynamic('train')\n",
    "    Y_val_d, y_test_sub = load_y_dynamic('test')\n",
    "    \n",
    "    X_train_d, X_val_d = load_signals('train'), load_signals('test')\n",
    "    X_train_d = X_train_d[y_train_sub]\n",
    "    X_val_d = X_val_d[y_test_sub]\n",
    "    \n",
    "    # fit and transform data\n",
    "    Scale = None\n",
    "    Scale = fit(X_train_d)\n",
    "    dump_file('Scale_dynamic.p','wb', Scale)\n",
    "    X_train_d = transform(X_train_d, Scale)\n",
    "    X_val_d = transform(X_val_d, Scale)\n",
    "    \n",
    "    return X_train_d, Y_train_d, X_val_d, Y_val_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayankgupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "X_train_d, Y_train_d, X_val_d,  Y_val_d = load_data_dynamic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape (3285, 128, 9) Test X shape (1387, 128, 9)\n",
      "Train Y shape (3285, 3) Test Y shape (1387, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Train X shape',X_train_d.shape,'Test X shape',X_val_d.shape)\n",
    "print('Train Y shape',Y_train_d.shape,'Test Y shape',Y_val_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model to distinguish Dynamic Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 122, 64)           4096      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 120, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                38430     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 48,795\n",
      "Trainable params: 48,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Clear session\n",
    "K.clear_session();\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "# Start session\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "K.set_session(sess)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=7, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3285 samples, validate on 1387 samples\n",
      "Epoch 1/20\n",
      "3285/3285 [==============================] - 1s 417us/step - loss: 0.4893 - accuracy: 0.7988 - val_loss: 0.2099 - val_accuracy: 0.9279\n",
      "Epoch 2/20\n",
      "3285/3285 [==============================] - 1s 350us/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.1145 - val_accuracy: 0.9517\n",
      "Epoch 3/20\n",
      "3285/3285 [==============================] - 1s 351us/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.1048 - val_accuracy: 0.9690\n",
      "Epoch 4/20\n",
      "3285/3285 [==============================] - 1s 341us/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.1344 - val_accuracy: 0.9495\n",
      "Epoch 5/20\n",
      "3285/3285 [==============================] - 1s 339us/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.0857 - val_accuracy: 0.9683\n",
      "Epoch 6/20\n",
      "3285/3285 [==============================] - 1s 336us/step - loss: 0.0310 - accuracy: 0.9924 - val_loss: 0.1000 - val_accuracy: 0.9726\n",
      "Epoch 7/20\n",
      "3285/3285 [==============================] - 1s 346us/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.0783 - val_accuracy: 0.9697\n",
      "Epoch 8/20\n",
      "3285/3285 [==============================] - 1s 409us/step - loss: 3.8390e-04 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9906\n",
      "Epoch 9/20\n",
      "3285/3285 [==============================] - 1s 426us/step - loss: 2.2239e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9856\n",
      "Epoch 10/20\n",
      "3285/3285 [==============================] - 1s 420us/step - loss: 2.4868e-04 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 11/20\n",
      "3285/3285 [==============================] - 1s 414us/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 0.2583 - val_accuracy: 0.9308\n",
      "Epoch 12/20\n",
      "3285/3285 [==============================] - 2s 460us/step - loss: 0.0376 - accuracy: 0.9900 - val_loss: 0.1201 - val_accuracy: 0.9704\n",
      "Epoch 13/20\n",
      "3285/3285 [==============================] - 1s 446us/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.0589 - val_accuracy: 0.9791\n",
      "Epoch 14/20\n",
      "3285/3285 [==============================] - 1s 374us/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0636 - val_accuracy: 0.9776\n",
      "Epoch 15/20\n",
      "3285/3285 [==============================] - 1s 354us/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0385 - val_accuracy: 0.9841\n",
      "Epoch 16/20\n",
      "3285/3285 [==============================] - 1s 342us/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.0859 - val_accuracy: 0.9740\n",
      "Epoch 17/20\n",
      "3285/3285 [==============================] - 1s 341us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0534 - val_accuracy: 0.9834\n",
      "Epoch 18/20\n",
      "3285/3285 [==============================] - 1s 340us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1136 - val_accuracy: 0.9690\n",
      "Epoch 19/20\n",
      "3285/3285 [==============================] - 1s 341us/step - loss: 3.3887e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9791\n",
      "Epoch 20/20\n",
      "3285/3285 [==============================] - 1s 334us/step - loss: 1.4385e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x635778668>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "adam = keras.optimizers.Adam(lr=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(X_train_d,Y_train_d, epochs=20, batch_size=32,validation_data=(X_val_d, Y_val_d), verbose=1)\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_accuracy 1.0 test_accuracy 0.9726027250289917\n"
     ]
    }
   ],
   "source": [
    "_,acc_val = model.evaluate(X_val_d, Y_val_d,verbose=0)\n",
    "_,acc_train = model.evaluate(X_train_d,Y_train_d,verbose=0)\n",
    "print('Train_accuracy',acc_train,'test_accuracy',acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving model\n",
    "model.save('final_model_dynamic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear tf session\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.4.4 Load and Split whole data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y_whole_data(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    return y\n",
    "    \n",
    "def load_whole_data():    \n",
    "    '''\n",
    "    Load and split whole data\n",
    "    '''\n",
    "    X_train, X_val = load_signals('train'), load_signals('test')\n",
    "    Y_train, Y_val = load_y_whole_data('train'), load_y_whole_data('test')\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayankgupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = load_whole_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train X (7352, 128, 9) shape of train Y (7352,)\n",
      "shape of test X (2947, 128, 9) shape of test Y (2947,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of train X',X_train.shape, 'shape of train Y',Y_train.shape)\n",
    "print('shape of test X', X_val.shape, 'shape of test Y', Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4.4.5 Final prediction pipeline </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "##loading keras models and picle files for scaling data \n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "model_2class = load_model('final_model_2class.h5')\n",
    "model_dynamic = load_model('final_model_dynamic.h5')\n",
    "model_static = load_model('final_model_static.h5')\n",
    "scale_2class = pickle.load(open('Scale_2class.p','rb'))\n",
    "scale_static = pickle.load(open('Scale_static.p','rb'))\n",
    "scale_dynamic = pickle.load(open('Scale_dynamic.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##scaling the data\n",
    "def transform_data(X,scale):\n",
    "    X_temp = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
    "    X_temp = scale.transform(X_temp)\n",
    "    return X_temp.reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting output activity\n",
    "def predict_activity(X):\n",
    "    ##predicting whether dynamic or static\n",
    "    predict_2class = model_2class.predict(transform_data(X,scale_2class))\n",
    "    Y_pred_2class =  np.argmax(predict_2class, axis=1)\n",
    "    #static data filter\n",
    "    X_static = X[Y_pred_2class==1]\n",
    "    #dynamic data filter\n",
    "    X_dynamic = X[Y_pred_2class==0]\n",
    "    #predicting static activities\n",
    "    predict_static = model_static.predict(transform_data(X_static,scale_static))\n",
    "    predict_static = np.argmax(predict_static,axis=1)\n",
    "    #adding 4 because need to get final prediction lable as output\n",
    "    predict_static = predict_static + 4\n",
    "    #predicting dynamic activites\n",
    "    predict_dynamic = model_dynamic.predict(transform_data(X_dynamic,scale_dynamic))\n",
    "    predict_dynamic = np.argmax(predict_dynamic,axis=1)\n",
    "    #adding 1 because need to get final prediction lable as output\n",
    "    predict_dynamic = predict_dynamic + 1\n",
    "    ##appending final output to one list in the same sequence of input data\n",
    "    i,j = 0,0 \n",
    "    final_pred = []\n",
    "    for mask in Y_pred_2class:\n",
    "        if mask == 1:\n",
    "            final_pred.append(predict_static[i])\n",
    "            i = i + 1\n",
    "        else:\n",
    "            final_pred.append(predict_dynamic[j])\n",
    "            j = j + 1 \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predicting \n",
    "final_pred_val = predict_activity(X_val)\n",
    "final_pred_train = predict_activity(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train data 0.9874863982589771\n",
      "Accuracy of validation data 0.9460468272819816\n"
     ]
    }
   ],
   "source": [
    "##accuracy of train and test\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy of train data',accuracy_score(Y_train,final_pred_train))\n",
    "print('Accuracy of validation data',accuracy_score(Y_val,final_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[492,   1,   3,   0,   0,   0],\n",
       "       [  3, 441,  27,   0,   0,   0],\n",
       "       [  4,   0, 416,   0,   0,   0],\n",
       "       [  0,   3,   0, 390,  94,   4],\n",
       "       [  0,   1,   1,  18, 512,   0],\n",
       "       [  0,   0,   0,   0,   0, 537]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion metric\n",
    "cm = confusion_matrix(Y_val, final_pred_val,labels=range(1,7))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAIxCAYAAABaRiKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd5xU9fX/8deBRVARWWzAgoKIwK70omABSxRYEA1oLDRrioo9NkyIvYBGDUm++RlFFBsoCisGxISo2ChKt4BA2F1sqwGNushwfn/cu+tsX5SZ2Zl5P33Mw7n3fu69nzMzy549n8+9Y+6OiIiISDKrl+gOiIiIiPxUSmhEREQk6SmhERERkaSnhEZERESSnhIaERERSXpKaERERCTpKaERERGRuDKzh8zsUzNbWcV2M7P7zWytmS03sx41HVMJjYiIiMTbFGBgNdsHAe3Dx4XAX2o6oBIaERERiSt3fwX4opomw4CpHngTaGpmLao7phIaERERqWuygE1Ry/nhuiplxLQ7IiIiUufYvo2cbTtid4Kvvl8FfBe15m/u/redOIJVsq7a72pSQiMiIpJutu2Aw/eP3fHnF3zn7r1+whHygdZRy62Awup20JCTiIhIOjKL3eOnmwWMDq92OgLY4u6bq9tBFRoRERGJKzN7AhgA7Gtm+cDvgQYA7v5XYA4wGFgLfAOcU9MxldCIiIikGyOhYzTufmYN2x24aGeOqSEnERERSXqq0IiIiKSjXTPXpc5QQiMiIpKOUiuf0ZCTiIiIJD9VaERERNLOLru8us5QhUZERESSnio0IiIi6SbBl23HQoqFIyIiIulIFRoREZF0pDk0IiIiInWLKjQiIiLpKLUKNEpoRERE0o4B9VIro9GQk4iIiCQ9VWhERETSUWoVaFShERERkeSnCo2IiEg60mXbIiIiInWLKjQiIiLpKLUKNKrQiIiISPJThUZERCTdpOB9aJTQiIiIpKPUymc05CQiIiLJTxUaERGRtGO6bFtERESkrlGFRkREJN2k4KRgVWhEREQk6alCIyIiko5Sq0CjCo2IiIgkP1VoRERE0pGuchIRERGpW1ShERERSUepVaBRQiMiIpJ2dNm2iIiISN2jCo2IiEg6Sq0CjSo0IiIikvxUoREREUlHumxbREREpG5RhUZERCQdpVhJI8XCERERkXSkhEZEfhIzm2Bmj4XPDzSzr82s/i4+xwYzO2FXHrMW5/y1mX0SxrPPTzjO12Z28K7sW6KY2SozG5DofsguYBbbRwIooRGp48Jf5p+Y2Z5R6843swUJ7Fal3P0/7t7Y3SOJ7stPYWYNgHuAE8N4in7sscL9P9p1vdv1zGyKmd1SUzt3z3H3BXHoksSDxfCRAEpoRJJDBnDpTz2IBfRzX7MDgEbAqkR3pC4wM823lDpP/7CJJIe7gavMrGllG82sn5ktMrMt4f/7RW1bYGa3mtlC4Bvg4HDdLWb2ejgkMtvM9jGzaWa2NTxGm6hj3Gdmm8JtS8zs6Cr60cbM3MwyzKxveOySx3dmtiFsV8/MrjWzdWZWZGZPm1mzqOOMMrON4bYbqnthzGx3M5sUtt9iZq+Z2e7htpPDYZL/hjF3itpvg5ldZWbLw/2eMrNGZnYo8H7Y7L9m9s/ouMq9rueHzw8xs3+Hx/nczJ6Kaudmdkj4fG8zm2pmn4X9HV+SYJrZ2LDvE83sSzNbb2aDqol7g5ldHfb/f2b2dzM7wMxeNLOvzGy+mWVGtZ9uZh+HfXzFzHLC9RcCZwO/LfksRB3/GjNbDvwvfE9Lh/7MbI6ZTYo6/lNm9lB175XUMRpyEpEEWAwsAK4qvyFMBF4A7gf2IRgqecHKzvsYBVwI7AVsDNedEa7PAtoBbwAPA82ANcDvo/ZfBHQLtz0OTDezRtV12N3fCIdbGgOZwJvAE+HmccApQH+gJfAlMDmMJxv4S9i3lmFMrao51USgJ9Av7N9vgR1hYvIEcBmwHzAHmG1mu0XtezowEGgLdAHGuvsHQE64vam7H1ddnKGbgXlhnK2AB6po9wCwN3BwGPto4Jyo7YcTJFP7AncBfzer9rfDcOBnwKHAUOBF4Ppw/3oEr3OJF4H2wP7AUmAagLv/LXx+V/h+DY3a50wgl+B12F7u3OcCo8zsODM7G+jNLqgiivxYSmhEksfvgEvMbL9y63OBD939UXff7u5PAO8R/IIrMcXdV4Xbvw/XPezu69x9C8Evu3XuPj/8xTUd6F6ys7s/5u5F4f6TgIZAh53o+/3A/4CSassvgRvcPd/di4EJwIiwAjICyHP3V8JtNwI7KjtoWN04F7jU3QvcPeLur4f7/QJ4wd1fCmOeCOxOkPiU9svdC939C2A2QdL2Y3wPHAS0dPfv3P21SvpaP+zTde7+lbtvACYRJG4lNrr7/wvnID0CtCAY/qrKA+7+ibsXAK8Cb7n7O2H8Myn7Hj4Unrfk9e5qZnvXENf97r7J3b8tv8HdPwZ+FfbzPmC0u39Vw/GkLqkXw0cCKKERSRLuvhLIA64tt6klP1RdSmwkqLyU2FTJIT+Jev5tJcuNSxbM7EozWxMOV/yXoMqwb236bWa/BAYAZ7l7SWJyEDAzHAr6L0FFKELwy7tldH/d/X9AVZNy9yWY67Kukm1lXpfw3Jso+7p8HPX8G6Ji3km/JZgK+XY4xHVuFX3djbLvVfn3qbQ/7v5N+LS6PtXqPTSz+mZ2RzjEtxXYENWn6lT2uYmWB9QH3q8siROJJyU0Isnl98AFlP0lWEiQIEQ7ECiIWvYfe8Jwvsw1BMMzme7eFNhCLa5lCPe9GRgWVoJKbAIGuXvTqEejsNKwGWgddYw9CIadKvM58B3BkFl5ZV6XcOimNWVfl9r6X/j/PaLWNS954u4fu/sF7t6SoPr055J5M+X6WlLJKVH+fYqVs4BhwAkEyWibcH3Je1jV56Omz82tBMloCzM78yf2UeLJ0BwaEUkcd18LPEXZuRFzgEPN7Kxw4uYvgGyCv553hb2A7cBnQIaZ/Q5oUtNOZtY67OvocF5KtL8Ct5rZQWHb/cxsWLhtBjDEzI4K57vcRBX/VoVVl4eAe8ysZViJ6GtmDYGngVwzO96Cy7CvBIqB13cq+uA8nxEkHiPDc5xLVBJlZqeZWck8ny8JEoFIuWNEwj7damZ7hbFfATy2s/35EfYiiL2IICm7rdz2Twjm9dSamR1DMP9ndPh4wMyyqt9LJHaU0Igkn5uA0nvShPdIGULwC7uIYPhjiLt/vovON5dgjs0HBEMk31HzUATA8QRVjBn2w5VOJZdB3wfMAuaZ2VcEE4YPD+NZBVxEMPl4M0GCkF/Nea4CVhBMXP4CuBOo5+7vAyMJJuJ+TjCnaKi7b6tl3OVdAFxN8BrnUDYx6g28ZWZfh3Fd6u7rKznGJQTVno+A18IY43Fl0FSC964AWE3wekf7O5AdDgE+V9PBzKxJeMyLw7lLr4XHeLiGScxSl6TYfWjM/UdXokVERCQJ2f67O6dXNlK7i0xetcTde8XuBBWpQiMiIiJJT3d/FBERSUcpNjqoCo2IiIgkPVVoRERE0k0CJ+/Giio0IiIikvRUoZFdynar5+ye2h+rHu0PS3QXYi4dLn5MsekDksI2bvgPn3/++S7+xBqxvMI+Ef+EpPZvHom/3TPgiOq+eib5LZyT+nd4T4fbOeh2KZIsjjz8qER3ISkooREREUlDqtCIiIhI0ku1IqUmBYuIiEjSU4VGREQkzRhQL4YlmkjNTXY5VWhEREQk6alCIyIikm4s9a70U4VGREREkp4qNCIiImlIFRoRERGROkYVGhERkbQT268+SAQlNCIiImkoxfIZDTmJiIhI8lOFRkREJM0YmhQsIiIiUueoQiMiIpJudGM9ERERkbpHFRoREZE0ZKhCIyIiIlKnqEIjIiKShjSHRiROTuo1gPceXMCHD7/KNaf/psL2A/fPYv4dT7DsL/P4111Pk7Vv89Jtd5x3HSv+bz4r/m8+p/cfGs9u75R5/5hHl+xu5HTozN13Tqywvbi4mJFnjianQ2eO7tufjRs2lm67+467yenQmS7Z3Xhp7kvx7PZOmTf3JbrmdOewjl2YeNekCtuLi4sZddZoDuvYhWP6DSiNsaioiIEnDGK/pgdw+bgr4t3tnZIW76NiTIkYo5nF7pEISmikTqpXrx6TL7qFQeNHk33BcZx57DA6Hdi+TJuJF4xn6vxn6PrrE7lp2h+5/ZxrARjc5zh6HHIY3X59EoePG8rVI37FXns0TkQY1YpEIlw27gqez5vJOyuWMP2p6axZvaZMmykPPUJmZlNWvb+CSy67mBuuuxGANavXMP3pGSxdvphZLzzHpZdcTiQSSUQY1YpEIlw+7gqem/0sS5cvZvqTlcfYtGlTVr63nEsuvYjx1wcxNmrUiN9NuJHb7rw1EV2vtXR5HxVj8seY6pTQSJ3Up0M31hZuYP3H/+H77d/z5IJZDOt7Ypk22Qe15+V3XwPgX8teL92efWB7/r38LSI7InxT/C3LPlrNwF4D4h1CjRa9vZh27Q6m7cFt2W233Tjt9BHkzcor0yZvVh5njzobgJ8PP5UF/1yAu5M3K4/TTh9Bw4YNadO2De3aHcyitxcnIIrqLS4X44hfjCBv9gtl2rww+wVGhjGeGhXjnnvuSb+j+tGoUaNEdL3W0uF9VIyBZI8xmmHUs9g9EkEJjdRJWfs0Z9NnhaXL+Z9vLjOkBLDsozUMP2owAKceOZAme+5Fs72asuyjNQzqPYDdGzZinyaZHNu1L633axnX/tdGYWEhrVq3Kl3OapVFQeHmKttkZGTQZO8mFBUVUVC4ucK+hYWF1DWFhYVktYrqZ1YWhQWFFduUiXFvioqK4trPnyJd3kfFmPwxpjolNAlkZvea2WVRy3PN7MGo5UlmdkX4/HIz+87M9o7aPsDMyv4JEaxfYGa9wudtzOxDMzspur2ZjTWzHWbWJWq/lWbWJnze2Mz+YmbrzOwdM1tiZhfs+lehcpVNVnP3MstX/e0W+nc+gqWTX6R/5yPI/2wz2yMRXlr6CnMW/YvX732OJ677E2+sWcr2yPZ4db3WyscDFeOupEnQphb71gW1izE5YqmK3seSNhX3U4x1m5nF7JEISmgS63WgH4CZ1QP2BXKitvcDFobPzwQWAafW9uBm1gqYC1zp7nMraZIP3FDF7g8CXwLt3b07MBBoVttz/1T5n28uU1VptW8LCos+KdNm8xefMPzmC+lx0SBumHIXAFu/+QqA2554gO6/GciJ152NmfFhwfp4db3WsrKyyN+UX7pckF9AyxbNy7VpWdpm+/btbN2ylWbNmpVZX7JvixYt4tPxnZCVlUVBflQ/Cwpo0bJFxTZlYtxCs2Zx+6j9ZOnyPirG5I8x1SmhSayFhAkNQSKzEvjKzDLNrCHQCXjHzNoBjYHxBIlNbTQH5gHj3X1WFW3ygBwz6xC9Mjxfn3DfHQDu/pm731n70H6aRe8vo31WG9oc0JoGGQ04Y8DJzHqz7JUD+zTJLP1L4LozLuaheU8BwYTiZns1BaBz2450aduJeUteiVfXa61X756sXbuODes3sG3bNqY/PYPcobll2uQOzWXao9MAePaZmfQ/tj9mRu7QXKY/PYPi4mI2rN/A2rXr6N2nVyLCqFbPcjHOeGoGuUMGl2kzeMhgHgtjnBkVY7JIh/dRMQaSPcYyLPUqNLoPTQK5e6GZbTezAwkSmzeALKAvsAVY7u7bzOxM4AngVaCDme3v7p/WcPipBAnJ9Gra7ADuAq4HxkStzwGWlSQzNTGzC4ELAWhUvza71CiyI8LFk29k7m2PUb9efR6a9xSrN37AH0ZfyeIPljP7zZcY0KUvt597Le7OKyve4qLJ4wFoUL8Br056BoCt33zNyDvHEdlR9644yMjI4N77JjF08DAikQhjxo4mOyebm35/Mz169WDI0FzGnjuGc8ecT06HzmRmZvLo448AkJ2TzfARw+neuScZGRn88f57qF9/17z2u1JGRgb33DeJk3NPIRKJMHrsqCDGCTfTo+cPMZ439nwO69iFzMxMpk6bUrp/x0Oy+WrrV2zbto3Zs/KYPed5OmV3Slg8lUmX91ExJn+Mqc4qGzeU+DGzacBsYBBwD0FC048godnH3a81s5XAqe7+oZndA6xz98lmNgC4yt2HlDvmAuBToDVwvLt/E64vbW9mY4FewGXAKoIhpdnAEKALcI67nxrudwNwGrC/u1c7u9b23s054oCf9qLUcd/OeT/RXYi5dPh3IZmqQJLejjz8KJYsXrpLP7AZLRt70/O71NzwRyq6+Y0l7l5lmcrMBgL3AfWBB939jnLbDwQeAZqGba519znVnVNDTolXMo+mM8GQ05sEFZp+wMJw0m574CUz2wCcQe2Gne4C3gKmm1mVlTh33w5MAq6JWr0a6BrO68Hdb3X3bkCTnQtNRESkLDOrD0wm+EM+GzjTzLLLNRsPPB3O4TwD+HNNx1VCk3gLCaoiX7h7xN2/IMhI+xIMQZ0JTHD3NuGjJZBlZgfV4tiXA1uBv1v1f45OAU4A9gNw97XAYuCW8IOHmTWCFPsmMxGRNGUkdA5NH2Ctu3/k7tuAJ4Fh5do4P/wRvTdQ43XwSmgSbwXB1U1vllu3xd0/J8hMZ5bbZ2a4HuB4M8uPevQtaeTBuMEYoAVBxaZS4QfqfmD/qNXnA/sAa81sCTCfslUcERFJYjFOaPY1s8VRjwujTp0FbIpazg/XRZsAjDSzfGAOcElN8WhScIK5e4RyQznuPjbqedtK9on+YpvdKznsgKi224DoW+wuCNdPIajMlLS7nyCpKVneCvyyFiGIiIiU93k1c2gqK+GUn7h3JjDF3SeFf6g/amaHVXexihIaERGRtJO4y6sJKjKto5ZbUXFI6TyCi1Vw9zfCaQ/7ElzwUikNOYmIiEg8LQLam1lbM9uNYApF+ful/Qc4HsDMOgGNgM+qO6gqNCIiIunGEnfrAnffbmYXE9zJvj7wkLuvMrObgMXhzWCvBP6fmV1OMBw11mu4n4QSGhEREYmr8J4yc8qt+13U89XAkTtzTCU0IiIiaSjV7i2pOTQiIiKS9FShERERSTMlN9ZLJUpoRERE0lCqJTQachIREZGkpwqNiIhIGqqnCo2IiIhI3aIKjYiISLoxXbYtIiIiUueoQiMiIpJmLLFfThkTqtCIiIhI0lOFRkREJA0ZqVWhUUIjIiKShjTkJCIiIlLHqEIjIiKShlShEREREaljVKERERFJQylWoFGFRkRERJKfKjSyS3U/5DAWvvBqorsRU7uP7JLoLsTcl1PeTHQXYq5Rxh6J7oJIwphpDo2IiIhInaMKjYiISNpJva8+UEIjIiKShlItodGQk4iIiCQ9VWhERETSUIoVaFShERERkeSnCo2IiEga0hwaERERkTpGFRoREZE0oxvriYiIiNRBqtCIiIikoVSr0CihERERSUMpls9oyElERESSnyo0IiIiaSf1vstJFRoRERFJeqrQiIiIpCFVaERERETqGFVoRERE0oxurCciIiJSB6lCIyIikoZSrECjhEZERCQdachJJE7mzX2JrjndOaxjFybeNanC9uLiYkadNZrDOnbhmH4D2LhhIwBFRUUMPGEQ+zU9gMvHXRHvbu+Uk7oew3uT5vHhvS9zzcm/rLD9wH1bMv+GqSy7M49/3TiNrGbNy2zfa/fG5E9+jQfG/j5eXd5p8+e9TO/OR9Ajuzf33n1fhe3FxcWcO/J8emT35oSjT+I/G/5Tum3lilWc2H8QfbsfRb+ex/Ddd9/Fs+u1Nu8f8+iS3Y2cDp25+86JFbYXFxcz8szR5HTozNF9+5d+VgHuvuNucjp0pkt2N16a+1I8u71TFGNqxJjKlNBInRSJRLh83BU8N/tZli5fzPQnp7Nm9ZoybaY89AhNmzZl5XvLueTSixh//Y0ANGrUiN9NuJHb7rw1EV2vtXpWj8nnTGDQneeRfdVAzuw3hE5Zh5RpM/Hs65j66ky6XjOEm559gNvPuKrM9ptPu4x/r3k7nt3eKZFIhKsvvZbpzz/Jm+8u5JmnZ/LemvfLtHl0yjT2btqUpasX8etLfsWE8TcBsH37dn55zm+Y9MDdvPHOa+TNe44GDRokIoxqRSIRLht3Bc/nzeSdFUuY/lTln9XMzKasen8Fl1x2MTdcF3xW16xew/SnZ7B0+WJmvfAcl15yOZFIJBFhVEsxBpI9xgqCmcGxeSSAEhqpkxa/vZh27Q6m7cFt2W233RjxixHkzX6hTJsXZr/AyFFnA3Dq8FNZ8M8FuDt77rkn/Y7qR6NGjRLR9Vrrc0hX1n68kfWfbuL7yPc8+cYLDOt1Qpk22a0O4eWVbwDwr1VvMqznD9t7tM3hgL33Zd7y1+La752xZNFSDm7XhjYHt2G33Xbj56edwpzZL5Zp8+LsFzlz5C8AGPbzofz7X6/i7vxz/r/IOSybzl0OA6DZPs2oX79+3GOoyaJyn9XTTh9B3qy8Mm3yZuVxdvhZ/XnUZzVvVh6nnT6Chg0b0qZtG9q1O5hFby9OQBTVU4yBZI8x1SmhkTqpsLCQrFatSpezsrIoLCis2KZ10CYjI4Mme+9NUVFRXPv5U2RlHsCmos2ly/lFH5OVeUCZNss2rmF4n5MAOLX3iTTZozHNGjfFzJg08nqunnZnXPu8szYXbiarVVbpcsuslmwu3FymTWHhx6VtMjIyaNKkCV8UfcG6D9dhZgwfchr9jziO+yY9ENe+11ZhYSGtWkd9VltlUVAhxh/aBJ/VJhQVFVFQuLnCvoWFZT/ndYFirNgmGWMsK/jqg1g9EkEJjdRJ7l5hXfkfktq0qcsq66tTNqarpt1B/059WHr7LPp36kN+0cdsj2znNz8byZx3F5D/xeYKx6hLavUeVdFm+/YIb77+Fn+b8lde/GceL8yaw7//+Uqsuvqj1e6zWnE/M6sy9rpGMZa0qbhfMsWY6pIioTGze83ssqjluWb2YNTyJDO7Inx+uZl9Z2Z7R20fYGZla4fB+gVm1it83sbMPjSzk6Lbm9lYM9thZl2i9ltpZm3C543N7C9mts7M3jGzJWZ2QTWxVOiLmU0xsxFRfXrfzJaZ2UIz6xCuHxIef5mZrTazX5rZDWb2bviIRD0fF3XsZWb2RC3Pt8jMukW1O9fMVpjZ8jDmYVXFtatlZWVRkJ9fulxQUECLli0qttkUtNm+fTtbt2yhWbNm8eriT5b/xce03ueHmFrt05zCLz8t02bzl58y/N6L6HHdydzw1D0AbP32a/q278bFJ45i/f0LmDjyWkYffSq3n3F1XPtfGy2zWlKQX1C6XFhQSPMWzcu1aVHaZvv27WzdupXMZpm0zGrJkUf3ZZ9992GPPfbgZyedwLJ3l8e1/7WRlZVF/qaoz2p+AS3LxZiV1bK0TfBZ3UqzZs3KrC/Zt0WLsp/zukAxlrRJ7hjLiOH0mUTlckmR0ACvA/0AzKwesC+QE7W9H7AwfH4msAg4tbYHN7NWwFzgSnefW0mTfOCGKnZ/EPgSaO/u3YGBwE/9rXq2u3cFHgHuNrMGwN+AoeH67sACd7/V3bu5ezfg25Ln7n5/GFcngvf4GDPbsxbn+zNwd7hvqzDmo9y9C3AEELffJj1792Tt2nVsWL+Bbdu2MeOpGeQOGVymzeAhg3ns0WkAzHxmJv2P7Z9UfxUtWrec9s0Pos1+rWhQvwFn9M1l1pKXy7TZZ6/M0piuG/YrHlowHYCRk6/koEuOoe24AVz12B1MfXUm1z15d9xjqEmPXt1Zt3Y9G9dvZNu2bTw7/TkGDRlYps3AIQN54rGnAHj+2dkcM+AozIzjf3Ysq1au5ptvvmH79u0sfPV1OnQ6NBFhVKtXuc/q9KdnkDs0t0yb3KG5TAs/q89GfVZzh+Yy/ekZFBcXs2H9BtauXUfvPr0SEUa1FGMg2WNMdclyH5qFwL3h8xxgJdDCzDKBb4BOwDtm1g5oDFwNXA9MqcWxmwNTgfHuPquKNnkESUEHdy+9RCM8Xx/gLHffAeDunwG7amLDK8BlwF4E71VReI5i4P1q9itxFvAowetzMvBE9c15g+C1A9gf+Ar4Ojzn1yXPyzOzC4ELAVof2LoW3apZRkYG99w3iZNzTyESiTB67Ciyc7K5acLN9OjZgyFDcxl77hjOG3s+h3XsQmZmJlOnTSndv+Mh2Xy19Su2bdvG7Fl5zJ7zPJ2yO+2Svu0qkR0RLp7yB+Ze9zD169XnoQXTWZ3/IX8YcSmL169k9pKXGdDpcG4/4yoc55U1i7jo4QmJ7vZOycjI4K4/3s7woacTiezg7DFn0im7I7f94Q669ezG4CEDGTX2bH517m/okd2bzGaZ/H3q3wBomtmU34z7NccfeSKY8bOBJ3DSoBMTHFFFGRkZ3HvfJIYOHkYkEmHM2NHBZ/X3N9Oj1w+f1XPHnE9Oh85kZmby6OOPAJCdk83wEcPp3rknGRkZ/PH+e+rkxGfFmBoxRjNSb1jMKhs3rIvMbANwDDCI4L3IIvgFvAW43d2PMbPx4bZbgY+APu7+qZkNAK5y9yHljrkA6EKQzPw5an1pezMbC/QC3gaOd/cxZrYSGBLue46770w1qEJfzGwKkOfuM8I+XeXui83saqCXu/8iHGI7GXiZIMF6oiSJCo/xtbs3LneuD4CfAR2Ai9395BrOdxmwv7tfb2b1gTkEydDLwLPuPrum+Hr07OEL33q1ti9HUtpjVNdEdyHmvpzyZqK7EHONMvZIdBdEauXIw49iyeKluzT72LNNpnccf+yuPGQZSy+YucTd41qmSpYhJwiqNP3Cxxvho2T59bDNGcCT4S/6Z4HTanHc+cAoM6vpX7fHgSPMrG1VDaLmtFQ3vb2qDDJ6/TQzexc4ErgKwN3PB44nSKyuAh6qrrNm1hv4zN03EiQkPcKKVmWmmVk+cA3wQHi+CMHw2QjgA+BeM5tQ3TlFRCR5lL8yaVc+EiGZEpqSeTSdCYac3gT6husWhpN22wMvhdWcMwjm09TkLuAtYLqZVTkE5+7bgUkEv/RLrAa6hvN6KJnTAjSp5nxFQPnEohnwedTy2eFcmFPcfVNUH1a4+1rYwVsAACAASURBVL0EVZfhNcR1JtAxfC3WhX2qap+zgbYESdvkqPO5u7/t7rcTvJ41nVNERJKEEprEWUgwzPOFu0fc/QugKUFS8wbBL/AJ7t4mfLQEsszsoFoc+3JgK/B3q/6dmAKcAOwH4O5rgcXALeEQDWbWiGDYqyofAi3DCbuE/esKvFvVDhZcSTUgalU3YGMVzUsmTp8GdCl5PYBhVJPgufv3wHiCKlQnM2tpZj1qe04REZFESqaEZgXB1U1vllu3xd0/J6ggzCy3z8xwPcDxZpYf9ehb0siDiURjgBYEFZtKufs24H6CCbMlzgf2Adaa2RKCIaxrKtm95BjFwEjg4XBYaQZwvrtvqTLyIEH6bXh59bvAH4Cx1bQ/Bihw94Koda8A2WZW5bWE7v4tQRXqKqABMNHM3gvP+Qvg0mrOKSIiSSTVLttOmknBkhw0KTg1aFKwSN0Rq0nBOb8/flcesoxF5z4T90nByXLZtoiIiOwqCZzrEitKaGLEzDoT3AMmWrG7H56I/oiIiKQyJTQx4u4rCCbSioiI1CmpeGO9ZJoULCIiIlIpVWhERETSUKpVaJTQiIiIpKFUS2g05CQiIiJJTxUaERGRdJPAG+DFiio0IiIikvRUoREREUlDmkMjIiIiUseoQiMiIpJmjNT76gNVaERERCTpqUIjIiKShlKtQqOERkREJA2lWD6jIScRERFJfqrQiIiIpBtLvSEnVWhEREQk6alCIyIiko5UoRERERGpW1ShERERSUOpNodGCY3sco4nugsx9e1jyxPdhZjbfXCHRHch5r6d836iuyAiu5ASGhERkTRjQL3UKtAooREREUk/+i4nERERkTpHFRoREZF0Y1BPFRoRERGRukUVGhERkTRjpN5l26rQiIiISNJTQiMiIpKG6sXwURMzG2hm75vZWjO7too2p5vZajNbZWaP13RMDTmJiIhI3JhZfWAy8DMgH1hkZrPcfXVUm/bAdcCR7v6lme1f03GV0IiIiKShBF7l1AdY6+4fAZjZk8AwYHVUmwuAye7+JYC7f1rTQZXQiIiIpJkETwrOAjZFLecDh5drcyiAmS0E6gMT3P0f1R1UCY2IiIjsavua2eKo5b+5+9/C55VlUuW/BDADaA8MAFoBr5rZYe7+36pOqIRGREQk7Vish5w+d/deVWzLB1pHLbcCCitp86a7fw+sN7P3CRKcRVWdUFc5iYiISDwtAtqbWVsz2w04A5hVrs1zwLEAZrYvwRDUR9UdVBUaERGRdGOJm0Pj7tvN7GJgLsH8mIfcfZWZ3QQsdvdZ4bYTzWw1EAGudvei6o6rhEZERETiyt3nAHPKrftd1HMHrggftaKERkREJM0YqTfnJNXiERERkTSkCo2IiEgaSuCN9WJCCY2IiEga0rdti4iIiNQxSmikzpo39yW65XSnc8euTLxrUoXtxcXFjD5rDJ07dqV/v2PZuGEjAEVFRQw6YTD7N23OFeOujHe3d8q8f8yjS3Y3cjp05u47J1bYXlxczMgzR5PToTNH9+1fGiPA3XfcTU6HznTJ7sZLc1+KZ7d3ykm9BvDegwv48OFXueb031TYfuD+Wcy/4wmW/WUe/7rrabL2bV667Y7zrmPF/81nxf/N5/T+Q+PZ7Z2SDu+jYkyNGEsYwZBTrB6JoIRG6qRIJMIV465k5uxnWbJ8EdOfnMGa1e+VafPIQ1Np2rQpK95bxsWXXsSN1wdX/DVq1IgbJ4zntjtvTUTXay0SiXDZuCt4Pm8m76xYwvSnprNm9ZoybaY89AiZmU1Z9f4KLrnsYm647kYA1qxew/SnZ7B0+WJmvfAcl15yOZFIJBFhVKtevXpMvugWBo0fTfYFx3HmscPodGD7Mm0mXjCeqfOfoeuvT+SmaX/k9nOuBWBwn+PocchhdPv1SRw+bihXj/gVe+3ROBFhVCsd3kfFGEj2GFOdEhqpkxa/vZiD2x1M24PbsttuuzHiF8PJm51Xpk3e7Bc4e9RZAJw6/BQW/HMB7s6ee+5Jv6P60bBRw0R0vdYWvb2YdlExnnb6CPJmlYtxVh5njzobgJ8PP7U0xrxZeZx2+ggaNmxIm7ZtaNfuYBa9vbiSsyRWnw7dWFu4gfUf/4fvt3/PkwtmMazviWXaZB/UnpfffQ2Afy17vXR79oHt+ffyt4jsiPBN8bcs+2g1A3sNiHcINUqH91ExBpI9xvIsho9EUEIjdVJh4WZatcoqXc7KymJzweZybQpp1boVABkZGTTZe2+Kiqq9kWSdEt1/gKxWWRQU1hRjE4qKiigo3Fxh38LC8l+FknhZ+zRn02c/9Cv/881lhpQAln20huFHDQbg1CMH0mTPvWi2V1OWfbSGQb0HsHvDRuzTJJNju/al9X4t49r/2kiH91ExVmyTjDGmOl3lJHVScJPIsirMyK9NmzqsNjFW0iRokySxV9an8nFf9bdb+NNFNzP2Z6fxyoq3yP9sM9sjEV5a+gq9O3Tl9Xuf47MtRbyxZinbI9vj1fVaS4f3UTGWtKm4XzLFWFbi5rrESswqNGZ2r5ldFrU818wejFqeZGZXhM8vN7PvzGzvqO0DzKxsvS9Yv8DMeoXP25jZh2Z2UnR7MxtrZjvMrEvUfivNrE34vLGZ/cXM1pnZO2a2xMwuqCaWNmb2bdh2jZm9bWZjyrU5xcyWm9l7ZrbCzE4J13c1s3ej2p1pZt+YWYNwubOZLY+KbXFU215mtiB8voeZTQuPvdLMXjOzg8zs3fDxsZkVRC3vFu53qpm5mXUsF8/KqNd5Sxjbe2Y2MardAWaWZ2bLzGy1mZW5TXUsZWW1JD+/oHS5oKCA5i3L/mXfMiuL/E35AGzfvp2tW7bQrFmzeHXxJ8uK6j9AQX4BLVs0L9emZbkYt9KsWbMy60v2bdGiRXw6vhPyP99cpqrSat8WFBZ9UqbN5i8+YfjNF9LjokHcMOUuALZ+8xUAtz3xAN1/M5ATrzsbM+PDgvXx63wtpcP7qBhL2iR3jKkulkNOrwP9AMysHrAvkBO1vR+wMHx+JsG3b55a24ObWSuCL6+60t3nVtIkH7ihit0fBL4E2rt7d2AgUNNvwnXu3t3dOxF8M+jlZnZO2JeuwERgmLt3BE4GJoYJ1QrgIDPbKzxOP+A9oHvU8sKo8+xvZoMqOf+lwCfu3tndDwPOAz52927u3g34K3BvybK7bwv3OxN4LexzVV4NX4fuwBAzOzJcfxPwkrt3dfds4NoaXqNdpmfvnqxbu44N6zewbds2Zjz1DLlDcsu0yR0ymGmPPg7AzGeeo/+x/ZPgr6If9Ordk7VRMU5/ega5Q8vFODSXaY9OA+DZZ2aWxpg7NJfpT8+guLiYDes3sHbtOnr36ZWIMKq16P1ltM9qQ5sDWtMgowFnDDiZWW+WvQJknyaZpe/bdWdczEPzngKCCcXN9moKQOe2HenSthPzlrwS3wBqIR3eR8UYSPYYo5ml3lVOsRxyWgjcGz7PAVYCLcwsE/gG6AS8Y2btgMbA1cD1wJRaHLs5MBUYH34rZ2XygGPMrIO7v1+yMjxfH+Asd98B4O6fAXfWNjB3/yisLk0CHgauAm5z9/Xh9vVmdjvBt4OOMrNFwOHAfKAnMJkgkXk7/P/8qMPfDYwHXix32hZA6TWC0TFVxcwaA0cSfAX7LGBCDXF9G1aTSiavtADmRW1fXsV5LgQuBGh9YOuaulUrGRkZTLpvIsNyTyES2cHosaPIzunEzRNuoUfP7uQOzWXMuaM5f+wFdO7YlczMTB6Z9nDp/p0OyeGrrV+xbds2Zs/KY9ac5+mU3bGaM8ZfRkYG9943iaGDhxGJRBgzdjTZOdnc9Pub6dGrB0OG5jL23DGcO+Z8cjp0JjMzk0cffwSA7Jxsho8YTvfOPcnIyOCP999D/fr1ExxRRZEdES6efCNzb3uM+vXq89C8p1i98QP+MPpKFn+wnNlvvsSALn25/dxrcXdeWfEWF00eD0CD+g14ddIzAGz95mtG3jmOyI66d+VIOryPijE1Ykx1Vtm44S47uNkG4BhgEMHE5yzgDWALcLu7H2Nm48NttwIfAX3c/VMzGwBc5e5Dyh1zAdCFIJn5c9T60vZmNhboRZAwHO/uY8IhliHhvue4+85Ug9oAeWFlpGRdU2Czu+9uZkvDYy6L2t4VeNjde5jZBGAHQQI0FxgTxn+6mX0InBQmSQsIkqO7gJuBr4CJ7j7AzLoRJBfrgJeBR9z9w6jzTQC+dvfoIaORwLHufp6ZvQ5c7O5Lo+Mp97plEiRXue7+sZmdBDwFvBOuf9jdq53p1qNnD3/trbr3V/SuVM9Sfy797oM7JLoLMfftnBr/JhCpE448/CiWLF66S8se+xy6vw964LRdecgypg388xJ3j2uZKtb/Mi8kqED0I0hk3ohafj1scwbwZFgteRaozSs8HxhlZnvU0O5x4Agza1tVAzO7IZxzsrNT0q3c8/KZYfS6ktehD7DI3dcBh5jZfkBjd/+o3L63EFRpSrn7u8DBBBWcZsAiM+tUQx/PBJ4Mnz8ZLlfm6HAez8cEic7H4Tnnhuf8f0BHgorafjWcU0REkkCqDTnFOqEpmUfTmWDI6U2gb7huYTjHpD3wUljNOYOqf+lGuwt4C5huZlUOm7n7doKqyDVRq1cDXcN5Pbj7reEclCY7FxrdgZK7Lq0iqAhF6xGeC4K4ewNHESR1EMzxOYMfErvofv8TaAQcUW791+7+rLv/BngMGFxV58xsH+A44MHwtb0a+IVVPsnkVXfvQvA+/TqsBpWc8wt3f9zdRxHMczqmqnOKiIgkSjwqNEOAL9w94u5fAE0Jkpo3CJKXCe7eJny0BLLM7KBaHPtyYCvw9yp+SZeYApwA7Afg7muBxcAtZlYfwMwasRP3AgqHbCYCD4SrJgLXRV1F1YZgPtCk8JxfAZuAsfyQ0LwBXEYlCU3oVuC3Uec8MhwSIryCKZuoOTWVGAFMdfeDwte2NbCeIKmqlLt/ANxOmACa2XElVbBwUnM74D/VnFNERJJALG+qV+durGdmTap71PL4Kwiubnqz3Lot7v45QYViZrl9ZvLDFTnHm1l+1KNvSSMPJv+MIZi4eldVHQiv9rkf2D9q9fnAPsBaM1tCMIR1TSW7R2sXXtq8BngaeMDdHw7P8W64/2wzew+YDfw2XF9iIdDQ3TeFy28QDOdUmtC4+xzgs+jzA/82sxUEc1oWA89U098zqfjaPgOcVUOcfyWYTN2WYALz4nA46g3gQXdfVMP+IiIicVflpGAz20QwByQ62SpZdnc/MPbdk2SjScGpQZOCReqOWEwK3vfQ/X3o5F/sykOWMeXEP8V9UnB18092zfW3IiIiIjFWq/vQmNkZwMHuflt4Q7sD3H1JbLsWf2bWGXi03Opidz88Ef0RERGJjdT76oMaExoz+xPQgODqltsIbor3V4KrdlKKu68AutXYUEREROqU2lRo+oU3h3sHgst4S74nSERERJKPWTJ8gebOqU1C8314zxaH0vub7Ihpr0RERCSmUm3IqTaXa0wmuNx3PzP7A8EXHdb6e49EREREYq3GCo27Tw3v1XJCuOo0d18Z226JiIhILKVWfab237ZdH/ieYNgp9W/CISIiIkmlxuTEzG4AngBaAq2Ax83sulh3TERERGLDSL0vp6xNhWYk0NPdvwEws1uBJQTf+SMiIiKScLVJaDaWa5cBfBSb7oiIiEg8pNpVTlUmNGZ2L8GcmW+AVWY2N1w+keBKJxEREZE6oboKTcmVTKuAF6LWv1lJWxEREUkalj431nP3v8ezIyIiIhIfRupdslyb73JqB9wKZAONSta7+6Ex7JeIiIhIrdUmQZsCPEyQ0A0CngaejGGfREREJJbC73KK1SMRapPQ7OHucwHcfZ27jweOjW23RERERGqvNpdtF1uQbq0zs18BBcD+se2WiIiIxFLaXLYd5XKgMTCOYC7N3sC5seyUiIiIyM6ozZdTvhU+/QoYFdvuiIiISKyVfPVBKqnuxnozCW6kVyl3/3lMeiQiIiKyk6qr0Pwpbr2QlGEG9SzV7m5QlnuVeX7K+HbO+4nuQswddPOJie5CXPzz0gcS3YWYa7tX+0R3IaZi9U9OOt1Y7+V4dkRERETixahHaiU0qf2ntIiIiKSF2lzlJCIiIikm1Yacal2hMbOGseyIiIiIyI9VY0JjZn3MbAXwYbjc1cxSf5aZiIhIigou4LCYPRKhNhWa+4EhQBGAuy9DX30gIiIidUht5tDUc/eN5cbaIjHqj4iIiMSBpdhVTrVJaDaZWR/Azaw+cAnwQWy7JSIiIlJ7tUlofk0w7HQg8AkwP1wnIiIiSSrVrnKqzXc5fQqcEYe+iIiISBwYiZu8Gys1JjRm9v+o5Dud3P3CmPRIREREZCfVZshpftTzRsCpwKbYdEdERETiwVLsywJqM+T0VPSymT0KvBSzHomIiIjspB/z1QdtgYN2dUdEREQkftJxDs2X/DCHph7wBXBtLDslIiIisjOqTWgsuKarK1AQrtrh7hUmCIuIiEhySbXLtqudERQmLzPdPRI+lMyIiIhInVObKc5vm1mPmPdERERE4sJi/F8iVDnkZGYZ7r4dOAq4wMzWAf8DjKB4oyRHREQkGVl6TQp+G+gBnBKnvoiIiIj8KNUlNAbg7uvi1BcRERGJk3SaFLyfmV1R1SNuPZS0Ne8f8+iS3Y2cDp25+86JFbYXFxcz8szR5HTozNF9+7Nxw8bSbXffcTc5HTrTJbsbL82tu/eBnDf3JbrmdOewjl2YeNekCtuLi4sZddZoDuvYhWP6DSiNsaioiIEnDGK/pgdw+bi6/eOYDu/jsYcczsKLH+fNcU9yyVEjK2y/6aRLePlXD/Pyrx7m9Uue4INrXyzdNv6EX/Pv30zl37+ZyrCc4+LZ7Z3y2vyFDOlzKoN6nsyDf3y4wvbFry/htAFn0XW/3sx7fn6ZbfdMuI9T+p3GKf1O48Vn58aryztt3tyX6JbTnc4du1b58zj6rDF07tiV/v2OLfPzOOiEwezftDlXjLsy3t2WUHUVmvpAY0jQ7B5Ja5FIhMvGXcEL/5hNVqssjjriaIYMzaVTdqfSNlMeeoTMzKasen8FTz81nRuuu5HHnpjKmtVrmP70DJYuX8zmws0MPmkIK9Yso379+gmMqKJIJMLl464g78VZZLXK4ugjjiF3yOAKMTZt2pSV7y1n+lPTGX/9jTz6+FQaNWrE7ybcyKpVq1m9anUCo6heOryP9awedwy+gtMfvZzCrZ8y94IHmfv+a3zw2YbSNr+b+0Dp8/P6DKdzi0MBOKF9X7q0OJTj/noODes3YOY5f+LltW/ydfE38Q6jWpFIhFt+eyf/79k/07zlAfzi+JEcO7A/7ToeXNqmRasW3DJ5AlP+9GiZff8971VWL3uPGa88wbbi7xk79HyOPuFIGjdpHO8wqhWJRLhi3JXMfvH58OexP7lDcumU3bG0zSMPTaVp06aseG8Z05+awY3X/46pjz9Co0aNuHHCeFavWlOnfx6jGVAvxb76oLpoNrv7Te7+h8oeceuhpKVFby+mXbuDaXtwW3bbbTdOO30EebPyyrTJm5XH2aPOBuDnw09lwT8X4O7kzcrjtNNH0LBhQ9q0bUO7dgez6O3FCYiieovLxTjiFyPIm/1CmTYvzH6BkWGMp0bFuOeee9LvqH40atQoEV2vtXR4H3tkdWL9F/ls/LKQ7yPbeW7lfAZ2OKrK9qd2PoFnVwTVpkP3a8MbG98lsiPCN99/x+qP13LcIUfEq+u1tmLJSg5s24rWbVrRYLcGDPr5SfzzxQVl2mQd2JIOOYdSr17ZXyvr3vuI3kf2JCMjgz323J0OOYfy2suvx7H3tbP47cUcXObncTh5s8t9Vme/wNmjzgLg1OGnVPh5bNioYSK6LqHqEhpVZiRhCgsLadW6VelyVqssCgo3V9kmIyODJns3oaioiILCzRX2LSwsjE/Hd0JhYSFZraL6mZVFYUFhxTZlYtyboqKiuPbzp0iH97F5k/0o3Ppp6XLh1s9o3mS/Stu22vsADmzagtfWLwVg1SdrOe6Qw9m9QUOa7bE3R7btQcsm+8el3zvj082f0TyreenyAS3359PNn1azxw86HHYor85fyLfffMuXRV+y6LXFfFzwSay6+qMVFm6mVaus0uWsrCw2F9T0WU2un8eyDLPYPRKhuiGn4+PWC6mUmd0AnAVEgB3AL4E7gauAyUBDoBmwOz/czbkFsLmS9acAC4Be7v65mTlwj7tfGZ7rKqCxu08Il0cCvyUYetwOLAKucvf/xi7iH1R2D8fyPySV3ebRzCrdUBcnv9UuxuSIpSrp8D5Wes+NKu5BesphJ5C3egE7fAcA/163iO4tO5F33l8p+t9/WbxpJZEdkVh290f5KZ/DI4/ry8p3VjFy4Dlk7pNJ195dqJ9Rt4YNoZYxJslnMl1VWaFx9y/i2REpy8z6AkOAHu7eBTgB2FSy3d0Pd/duwO+Ap9y9W/g4oIr1G8qdohj4uZntW8m5BwKXA4PcPYfg8v3XgQN2faSVy8rKIn9TfulyQX4BLVs0L9emZWmb7du3s3XLVpo1a1Zmfcm+LVq0iE/Hd0JWVhYF+VH9LCigRcsWFduUiXELzZo1i2s/f4p0eB83b/20TFWlZZP9+Pirzytte8phx/PsyrITZv/46lSO/+s5nP7o5ZgZH32xqdJ9E+mAlvvzccHHpcufFH7Kfs0rr0JV5pdXns8zrzzJgzP/grtzULsDY9HNnyQrqyX5+QWlywUFBTRvWfaz2jLq85yMP4/lpVqFJrVmBKWWFsDn7l4M4O6fu/uurLdvB/5GkLiUdwNBNaYgPHfE3R9y9/d34fmr1at3T9auXceG9RvYtm0b05+eQe7Q3DJtcofmMu3RaQA8+8xM+h/bHzMjd2gu05+eQXFxMRvWb2Dt2nX07tMrXl2vtZ7lYpzx1Axyhwwu02bwkME8FsY4MyrGZJEO7+M7he9x8D6tObBpCxrUz+CUw05g7vsLK7Rrt09r9t59LxZvWlm6rp7VI3P3JgBkH9CO7APasWDdorj1vbYO65HDfz7aRP7GAr7f9j0vPjuXYwf2r9W+kUiE/34RFHbfX/UBH6z6kH7H1r15Qj1792RdmZ/HZ8gdUu6zOmQw0x59HICZzzyXdD+Pqa7Gb9uWhJkH/M7MPgDmE1Rb/r2LzzEZWG5md5VbnwMsre1BzOxC4EKA1ge23iUdy8jI4N77JjF08DAikQhjxo4mOyebm35/Mz169WDI0FzGnjuGc8ecT06HzmRmZvLo448AkJ2TzfARw+neOZiI+Mf776lzV8ZAEOM9903i5NxTiEQijB47Kohxws306PlDjOeNPZ/DOnYhMzOTqdOmlO7f8ZBsvtr6Fdu2bWP2rDxmz3m+zNVDdUE6vI+RHRGum3MPT466h/pWjyfeeYH3P1vPb489j2WF75UmN6d2/hnPr3y5zL4N6mfw/LmTAfi6+Bt+8+xNdXLIKSMjg+vvuoZfjriISGQHp559Mod0asefbvsLOd2zOXZQf1YsXcVlo65k65atLPjHK0y+4688/8YMtn+/ndGDzwOg8V57csf/3UJGRt371ZORkcGk+yYyLPcUIpEd4c9jJ26ecAs9enYnd2guY84dzfljL6Bzx65kZmbyyLQfLl/vdEhOmZ/HWXOeL3OFVF1UL8Wmypq+b7LuMrP6wNHAsQTzZ64FxhJUTxaHbcYSzIu5uNy+Fdab2QZ+mEPztbs3NrObgO+Bbwnn0JjZF0Bbd99iZp2BR4G9gOvd/anq+tyzVw9f+NZrPz34OiwdfmbS4a/Og24+MdFdiIt/XvpAzY2SXNu92ie6CzF11OHHsHTJ0l36Q9k6u5Vf+vi4XXnIMq7ufs0Sd49rSVVDTnVYONSzwN1/D1wMDI/Baf4InAfsGbVuFcG8Gdx9RTgn50WCScYiIiJ1jhKaOsrMOphZ9J8d3YCNVbX/scLJ308TJDUlbgcmmlmrqHVKZkREUkX45ZSxeiRC3RvIlBKNgQfMrCnBBN61BPNUZsTgXJMIKkAAuPscM9sPeDEc9vovsBKou/csFxGRtKaEpo5y9yVAv0o2DSjXbgowpZL9K6x39zZRzxtHPf8E2KNc20eAR3au1yIikhys8nsoJTENOYmIiEjSU4VGREQkzRjBfZBSSWpFIyIiImlJFRoREZE0lGr3m1JCIyIikoY0KVhERESkjlGFRkREJO0k7gZ4saIKjYiIiCQ9VWhERETSjKE5NCIiIiI/iZkNNLP3zWytmV1bTbsRZuZmVuM3d6tCIyIikoYSNYcm/I7AycDPgHxgkZnNcvfV5drtBYwD3qrNcVWhERERkXjqA6x194/cfRvwJDCsknY3A3cB39XmoEpoRERE0o2BWb2YPYB9zWxx1OPCqLNnAZuilvPDdT90z6w70Nrd82obkoacRERE0k7Mv237c3evat5LZSf20o1BRnQvMHZnTqgKjYiIiMRTPtA6arkVUBi1vBdwGLDAzDYARwCzapoYrAqNiIhImgm+bTthl20vAtqbWVugADgDOKtko7tvAfYtWTazBcBV7r64uoOqQiMiIiJx4+7bgYuBucAa4Gl3X2VmN5nZyT/2uKrQiPz/9u48Xq75/uP4651E7JGgiCREIlQikdVaS1UVEWorqSKtVquttVSLolq1JNRS9SutBlUlljairT1qCbIQIVqiErKondhC4vP745wbk5t7b26YmTPnzPvpMQ9zzvnOzOeb3Jv7uZ/zXczM6lCWu21HxN+Bvzc6d1ozbXdqzXu6QmNmZma55wqNmZlZHWrjrQ/MzMzMaosrNGZmZnVGZDuGphKc0JiZmdUdNazoWxhOaMyWU9F+q6lXM05p9YrqudbhgP5Zh1Bx7980fdmNcsz/5LSOExozM7M65EHBZmZmZjXG4zhvyQAAIABJREFUFRozM7M6IxXv9rkrNGZmZpZ7rtCYmZnVIXkMjZmZmVltcYXGzMys7qhwY2ic0JiZmdUhT9s2MzMzqzGu0JiZmdWZZC+nYtU0itUbMzMzq0uu0JiZmdUdedq2mZmZWa1xhcbMzKwOFW3atis0ZmZmlnuu0JiZmdWhoo2hcUJjZmZWh3zLyczMzKzGuEJjZmZWZ4S3PjAzMzOrOU5orGbd8c876Ne7P3027cvIc0ctdX3BggV8Y/ih9Nm0L9tvsyOzZs5afG3kOSPps2lf+vXuz52331nNsJeL+1iMPt55+10M7DOELTYbyAXn/Xqp6wsWLGDE17/FFpsN5Ivb7cKsmS8AMGniZLYbvD3bDd6ebQd9gVv/Oq7aobfaVwbsyL8vvZtnLxvPSfseudT1DT7XhbvOvJapF/6De3/5F7qstd7ia93WXp/bz7ia6ZfcxVOX3MmG63StZuitVg9fq4sp2W27Uo8sOKGxmrRo0SKOPfp4/jbuFh6bNpkx14/h6elPL9Fm9JVX0alTR576zzSOOvaHnPLTnwHw9PSnGXPDjUx5YhJjb/srxxx1HIsWLcqiGy1yHxNF6OOPjjmRm24dw8SpD3Pj9Tfx7+n/XqLN1X+8ho6d1mDq01P4wdFHcvrJZwDQu89m3PfwvTw46X5uHncjx/zgOBYuXJhBL1rWpk0bLv3umex+5gh6H/Vlhm+/F5t13XiJNqNGnMzV997MFsfuzpnXX8TZh/x48bWrj72AkbdcTu+jdmHLE/fm5TdfrXYXlqkevlaLzgmN1aSJj06iZ88ebNRjI9q3b88BX9ufcWOX/O113NhxHHzIwQDsu98+jL9nPBHBuLHjOOBr+7PiiivSfaPu9OzZg4mPTsqgFy1zHxN57+OkiZPp0bMHG/XoTvv27dnva/ty261/X6LNbbf+g+GHDAfgq/vtzfh77yMiWGWVVWjXLhnK+MEHC2p21smWvfozY94snv/fi3y08CP+8sCt7L3Vrku06d2tF3c/8SAA906bwN5bfhmAzbpuTLs2bblr6gMAvPvBe7z/4QfV7UAr1MPXamOiTcUeWXBCYzVp7ty5dO32SVm6S9cuzJk7r9k27dq1o8MaHXjttdeYM3feUq+dO3dudQJfDu7j0m3y2Md5c+bRtWuXxcfrd1mfuY36OG/O3MVtGvr4+muvA8kP0i232IZtBm7Hhb+5YHGCU0u6rLkuL776yZ/97Nfm0WXNdZdoM3Xm0+y3ze4A7LP1V+iwyuqsuXpHNunSgzfffZubTvo/plxwG+cd9lPatKm9Hz318LVadLX3VVVQkk6R9JSkJyQ9Lune9P8zJL2VPn9c0rZp+89J+kjSdxu9z0xJN5Uc7y9pdPp8hKRXJD0m6VlJtze8X3p9tKT90+fjJU0quTZY0viS4y3TNs9KmiLpNkl9K/Xn01hELHWu8W+vTTRJ2rTitbXAfWxos/Tr6qGPpG2GbDmYR6dOYPxDd3P+eb/mgw9qr3rR1J97sGSnTvjjWezYZyumXHAbO/bZmtmvzmPhokW0a9OW7XsP4YTRZzHkhL3osd4GjNh5/2qF3mr18LXamMfQ2HKTtA2wJzAwIvoBuwAHR0R/4NvA/RHRP308lL7sAOBhYHgTbzlYUp9mPu76iBgQEb2Ac4CbJW3WTNt1JO3eRLzrAjcAJ0dEr4gYCJwN9Gxdjz+7Ll26MPvF2YuP58yew/qd12vUZv3FbRYuXMjbb73NmmuuucT5htd27ty5OoEvB/exoU2++7h+1/WZPXvO4uO5c+bSuVEfS9t80sdOS7TZdLNNWXXVVZj+1JLjNmrB7Ndeotva6y8+7rpWZ+a+/vISbea98TL7nfs9Bh4/lFOuHQnA2+/NZ/ZrL/HY89N5/n8vsujjRfz1kTsY2GPzqsbfGvXwtVp0TmiqozPwakQsAIiIVyNiWfXI4cCPgK6SujS6Ngo4eVkfGhH3ApcDRzTTZCRwahPnfwhcVZJcEREPRMRfl/WZ5TJ4yCBmzHiOmc/P5MMPP2TMDTcydNjQJdoMHTaUa6+5FoCbb7qFHb+4I5IYOmwoY264kQULFjDz+ZnMmPEcQ7YcXK3QW819TOS9j4MGD+S/M55j5vOz+PDDD7nphpvZY88lf0/YY8/duO6a6wD4601/Y8eddkASM5+ftXgQ8AuzXuDZZ2aw4YYbVL0PyzLx2an06tyd7ut0ZYV2K3DQF4Yx9tElZ/KstXqnxb+Z/3S/73Pl3Tckr50xlU6rrsHaHdYEYOe+2zL9xWer24FWqIev1VIi2fqgUv9lofZu1hbTHcBpkp4B7iKpotzXXGNJ3YD1IuJRSTcABwIXlDS5Afi+pI2bfIMlTQG+28y1CcA+kr4IzC853we4qhXv3RDvEaRJU7cNurX2ZS1q164dv77ofIbtsTeLFi3isBGH0rtPb848/RcMHDyQPYcNZcS3DuNbh32bPpv2pVOnTlzz5yTk3n16s9/++zGg7yDatWvHhRdfQNu2bcsSVzm5j8Xp48gLz2Ofofux6ONFHHLYwWzWZzN+ecavGDioP3sM24NDv3kIR4z4HltsNpBOnTrxxz/9AYAJD07g1yMvYoUV2tGmTRsuuHgUa629VsY9WtqijxfxwytO4/bTr6Zt27ZcedcNTH/xWX4+/DgmzZjGrRPvYqfNt+bsQ35MRPCv6Y/yg9+dBsDHH3/MCaPP4u4zr0USk597kivu/EvGPVpaPXytLkm0ycFtseWhpu4bWvlJagtsD3yRJMH4SUSMlrQTcEJE7FnS9kSgY0ScIqkf8IeIGJJemwkMBvYCtgP+AewZESMkjQAGR8QPS95rH+CIiNg9HWszLiJuTMfLnAB0AE4BTgJGRcROkm4mqdD8LX2PR9J2d0TEMS31c9DggfHgIw98lj8qs6r46OMPsw6hKjoc0D/rECru/ZumZx1CRW231ReYPGlKWbOPXv02jgvHnVfOt1zCnhvuNzkiqlqm8i2nKomIRRExPiJOJ7mls18LzYcDI9LkZSywhaRejdpcA+wALKs+PQBo9qZ8RNwDrARsXXL6KWBgSZutgJ8Bayzjs8zMLCeKdsvJCU0VSNq0UULSH5jVXFtg1YjoEhHdI6I7yYDcg0rbRcRHwK+BY1v43B1JbgVdsYwQzwJ+XHJ8KUlCtW3JuVWW8R5mZmaZ8Ria6lgNuERSR2AhMIPmB+oOB25pdO4m4C/ALxqd/wNLD+o9UNIXSBKQ54H9IqLFaRMR8XdJr5QcvyTpQODcdEDyy8CrwJktvY+ZmeVHHqaWLw8nNFUQEZOBbZu5Nh4YX3J8RhNtngB6p8+7l5xfAKxfcjwaGN1CHCNKnu/U6NqgRscPAzs2915mZma1xAmNmZlZnUmmbRdr1EmxemNmZmZ1yRUaMzOzupPdFgWV4oTGzMysDrXJaHp1pfiWk5mZmeWeKzRmZmb1RsWbtu0KjZmZmeWeKzRmZmZ1pmG37SJxhcbMzMxyzxUaMzOzOuQxNGZmZmY1xhUaMzOzuqPCbX3ghMbMzKwOtfEtJzMzM7Pa4gqNmZlZnfG0bTMzM7Ma5AqNmZlZHfK0bTMzM7Ma4wqNmZlZ3ZHH0JiZmZnVGldozMzM6lDRxtA4oTEzM6szAtoU7CZNsXpjZmZmdckVGjOrSyu0aZ91CFXx/k3Tsw6h4lbebZOsQ6isZ14u/3uqeLecXKExMzOz3HOFxszMrO542raZmZlZzXGFxszMrA55DI2ZmZlZjXGFxszMrA4VbQyNExozM7M6I4qX0PiWk5mZmeWeKzRmZmb1yIOCzczMzGqLKzRmZmZ1xwvrmZmZmdUcV2jMzMzqkBfWMzMzM6sxrtCYmZnVoaKNoXFCY2ZmVoeKltD4lpOZmZnlnis0ZmZmdUZ4ULCZmZlZzXGFxszMrO54YT2zqrnjn3fQr3d/+mzal5Hnjlrq+oIFC/jG8EPps2lftt9mR2bNnLX42shzRtJn0770692fO2+/s5phLxf30X10H2vHH340iv/d8DjTLr+r2TYXff9Mnh39AFN/dycDNt588flDv7w/z4y+n2dG38+hX96/GuHmmqTdJP1H0gxJP2ni+vGSpkt6QtLdkjZc1ns6obGatGjRIo49+nj+Nu4WHps2mTHXj+Hp6U8v0Wb0lVfRqVNHnvrPNI469oec8tOfAfD09KcZc8ONTHliEmNv+yvHHHUcixYtyqIbLXIfE+6j+1grRt8xht1O/kaz13ffcmd6ddmIXiO+wBEXnsRlR58NQKfVO3L6Icex1VHD2PKHe3L6IcfRcbU1qhX2p6YK/tfi50ptgUuB3YHewHBJvRs1ewwYHBH9gBuB85bVHyc0VpMmPjqJnj17sFGPjWjfvj0HfG1/xo0dt0SbcWPHcfAhBwOw7377MP6e8UQE48aO44Cv7c+KK65I942607NnDyY+OimDXrTMfUy4j+5jrbh/2iO8Pv/NZq/vvc2uXH3XjQA88vQUOq7WgfXWXIevDN6ROyffzxvz3+TNd97izsn3s9uQnaoUdS5tCcyIiP9GxIfAX4C9SxtExL0R8V56+DDQdVlv6oTGatLcuXPp2u2Tr98uXbswZ+68Ztu0a9eODmt04LXXXmPO3HlLvXbu3LnVCXw5uI9Lt3Ef3cda1mXt9Xjx5U9in/3qPLqsvR5d1lqPF19pdH6t9bIIsfWUzHKq1GMZugAvlhzPTs8153DgH8t6Uyc0OSHpnRauTZV0XcnxEZKuLznuIOk5SRtJGi1p//T8eEmTStoNljS+5HjLtM2zkqZIuk1S37J3rgkRsdS5xt8kTTRJ2rTitbXAfWxos/Tr3MfaUg99bI2m4o6Ips/TxB9IjanwLae1JU0qeRyxxEcvrck/MEnfAAYDI5fVHyc0OSdpM5K/xx0krZqevgLoKmmX9PhM4MqIeL6Jt1hH0u5NvO+6wA3AyRHRKyIGAmcDPcveiSZ06dKF2S/OXnw8Z/Yc1u+8XqM26y9us3DhQt5+623WXHPNJc43vLZz587VCHu5uI8NbdzH0te6j7Vr9ivz6LbO+ouPu67dmbmv/Y/Zr86j2+eWPl/nXo2IwSWPy0uuzQa6lRx3BZYq26U/w04B9oqIBcv6QCc0+fd14BrgDmAvgEh+nToSuFDSYOBLNJ/djgRObeL8D4GrIuKhhhMR8UBE/LWMsTdr8JBBzJjxHDOfn8mHH37ImBtuZOiwoUu0GTpsKNdecy0AN990Czt+cUckMXTYUMbccCMLFixg5vMzmTHjOYZsObgaYS8X9zHhPrqPeTF2wh0cuksyg2mrzQby1rvzeen1l7l90n3sOmgHOq62Bh1XW4NdB+3A7ZPuyzjaljUsrJfRLaeJQK/0rkF74CBg7BLxSQOA35EkMy+3pk9ehyb/DgS+DGxKkoRcBxART0i6Hbgb+Go68KopE4B9JH0RmF9yvg9wVWsCSEuJRwB026DbMlq3Trt27fj1ReczbI+9WbRoEYeNOJTefXpz5um/YODggew5bCgjvnUY3zrs2/TZtC+dOnXimj8n4fbu05v99t+PAX0H0a5dOy68+ALatm1blrjKyX10H93H2vLnk3/DTv22Ye011uTFP0/k9KvPZ4V2yY/J3437E39/9B722GpnZlz1AO8t+IBvjjoegDfmv8kvrr2Iib+5DYAzr72QN1oYXFzvImKhpB8CtwNtSe4gPCXpTGBSRIwl+WV7NWBMmiC9EBF7tfS+aureqNUeSe9ExGqNzg0BLoyI7dJpcLOAvhHxRnq9BzAuInqXvGZ0eu7GdLzMCUAHkrLeScCoiNhJ0s0kFZq/pa97JG13R0Qc01ycgwYPjAcfeaBs/TYzW5aVd9sk6xAq65GXibc/LOvAo80H9Ikx9/65nG+5hN6d+k+OiKqW4nzLKd+GA5+XNBN4jiTh2K/k+sfpo0URcQ+wErB1yemngIElbbYCfgbU/uIKZmZWd5zQ5JSkNsABQL+I6B4R3Unm8Q//lG95FvDjkuNLgRGSti05t8qnfG8zM6sxFZ7lVHUeQ5Mfq0iaXXJ8ATAnIuaUnPsX0FtS54hYcpGIZYiIv0t6peT4JUkHAudK6gK8DLxKMmPKzMyspjihyYmIaKqadkGjNouAziXHM4HNG7UZUfJ8p0bXBjU6fhjY8VOGbGZmNSyv6wE1x7eczMzMLPdcoTEzM6tDWY11qRQnNGZmZnVGFC+h8S0nMzMzyz1XaMzMzOpOq7YoyBVXaMzMzCz3XKExMzOrS67QmJmZmdUUV2jMzMzqjbywnpmZmVnNcYXGzMysDhVtHRonNGZmZnWoaAmNbzmZmZlZ7rlCY2ZmVmfkhfXMzMzMao8rNGZmZnXIY2jMzMzMaowrNGZmZnXIFRozMzOzGuMKjZmZWR0q2iwnJzRmZmZ1yLeczMzMzGqMKzRmZmZ1pogL6zmhsbKaMvmxV1dut+qsKn/s2sCrVf7ManMfi8F9LIZq93HDKn5WbjmhsbKKiM9V+zMlTYqIwdX+3GpyH4vBfSyGovTRY2jMzMzMaowrNGZmZnXJFRqzWnN51gFUgftYDO5jMdRDH3NHEZF1DGZmZlZFWwzsF/98YFzF3n/9VTecXO1xRr7lZGZmVoeKNm3bt5zMzMws91yhMTMzq0uu0JiZlY2ktSTtI2lQ1rGYWX45obHckHS4pBNLjudIelvSfElHZhlbuUgaJmnDkuPTJE2VNFbSRlnGVi6SxknaPH3eGXgS+BZwjaRjMw2uTCR1kNSr5PgASYemj3WzjK1cJPWRtFfJ8a8lXZk+BmYZWzkVuZ+q4CMLTmgsT74HXFly/HJEdAA+BwzPJqSyOwt4BUDSnsA3SH7YjwX+L8O4ymmjiHgyff5N4M6IGAZsRdLXIhgFbFdyfDYwBNgB+HkmEZXfOSy5/P9XgNuAe4HTMomoMuqln7nnMTSWJ20i4rWS4zEAEfGBpJUziqncIiLeS5/vC/whIiYDkyV9P8O4yumjkudfAq4AiIj5kj7OJqSyGwJ8t+R4fkQcBSDpgWxCKrvOEfFQyfHbEXETgKTvNvOaPCpoP7OspVSGExrLkzVKDyLiVwCS2gBrZRJR+UnSasB7JD/sf1tybaVsQiq7FyUdBcwGBgL/BEiT0hWyDKyM2sWSi3wdUvK8Y7WDqZDVSw8iYuuSw3WqHEsl1Us/c8+3nCxP7pD0yybOnwncUe1gKuRC4HFgEvB0REwCkDQAmJdlYGV0ONAHGAEcGBFvpue3Bv6YVVBl9rGk9RoOGm6xSeoCFKUKNVfSVo1PStoamJtBPJVSyH5KyTo0lXpkwRUay5MTgd9LmgFMTc9tQfLD/9uZRVVGEXGlpNtJfvObWnLpJZIEIPci4mWS8VCNz98r6b8ZhFQJI4FbJf0IeCw9N5BkbM3IzKIqr5OA6yWNBqak5wYBhwEHZhVUBdRLP3PPCY3lRkS8CwyX1IPkN3yA6RHxXIZhlV1EzAHmNDrdATgB+E71Iyo/SdsAXYB/RcTLkvoBPwG2B7plGlwZRMSfJL0K/JJPvlafBE6LiH9kF1n5RMSjaZXiB3ySbD8FbB0R/8sssDKrl34WgRMayw1JG6RPF1JSvWg4HxEvZBFXOaU/2EcB6wN/BS4hGUezFXB+hqGVjaSRwJ4kt9ZOkjQO+D7wK4ozy4mI+Cfp+KCiSn+gF36mT1H7KQ8KNsvMbUCw5ND8IJm2vQ7QNougyuwK4DJgArAbSYn7z8DBEfFBloGV0VBgQDo7rRPJOIR+EfFsxnGVjaSWfvhFRPyiasFUiKR7Sb7/mhIR8aVqxlMp9dLPInBCY7kREX1LjyV1J7m/vQvJb/dFsGJEjE6f/0fSCcBPImJRhjGV2/sNyVlEvCHpP0VKZlLvNnFuVZIB0WsBuU9oSG6BNrY18GPg5SrHUkmF7acrNGYZS1dgPYVPbsMcHREftfyq3FgpndHU8C/NO0A/pdMGImJKs6/Mj56SxpYcdy89joi9mnhNrkTE4tuDklYHjiFZRPAvFOTWYbo+EgCSdgR+BqwIfK8o44SgfvpZBE5oLDfS5fJPIRlkeR5weMEqF5DMZrqgmeMAdq56ROW3d6PjQvyAb0zSmsDxwMHAVcDAiHgj26jKS9JXSH7AfwCcFRH3ZhxSRdRLP/POCY3lyVTgRZKxNFsCW5audxARR2cUV9lExE5Zx1BpEXFf1jFUWjrweV/gcqBvRLyTcUhlJ2kiyfi1kSRjvijd26gg1cS66WcROKGxPDmc5gfnFYKkfVu6HhE3VyuWSpE0jab/HkUyyLJflUOqhB8BC4BTgVNKEu+GPnbIKrAyepfkluj+6aNUUaqJUOB+ZrUAXqU4obHcKBksW2TDWrgWQO4TGpIp24UWEYVfhb0eqolQP/0sAic0lhuSbqWFCk1BBpN+s7lrktatZiyVEhGzmjovaTvg6yQLmOVaOn6mWRHxerViqZR6qCZC/fSzCJzQWJ6MyjqAapO0BrAfyQ/6zUhW1y0MSf1J+vY14HmKUYECmMzSayY1CKBHdcOpiHqoJkJh+ylP2zbLUPuIuLOpC5LOBQox2DTddXovkh/0A0l2+/0q8K8s4yoXSZsABwHDgdeA6wFFxBczDay8dmquElUULVUTC+aMov9dFkXh7/NaoVwqaWjpCUlt0k3jtsgmpPKSdC3wDLAr8BugO/BGRIyPiKLs0vxv4EvAsIj4QkRcAhRt+v0tWQdQDZI2lXS+pNvSx6g0YS2SuyX9RFIBCwCq4KP6nNBYnuwKnN9wTzutZIwF2tNyWThPNgfeAJ4G/p2us1O0mV37kayvc6+kKyR9iaz+BaycovVnKekGo+NJZgBdTrJtx7vA+HQzx6IYAKwLTJa0Q9bBWPMKmHFaUUXETEm7ALdLWgc4BHgkIo7POLSyiYgtJH2e5HbTXZJeBlaXtF5EvJRxeGUREbcAt0haleRW2nHAupIuA26JiDsyDbA8uki6uLmLRVgziWSzxuERMb7k3F8l3QOcDuyeSVRlFhHzgeMkDSKp1swGPibnywxkV0epHEUU7Zc/K6qSxaw6A1cDd5KsGAwUc4ErSYNJxpocAMyOiG0zDukzk9QuIhY2OrcmSR8PjIjcruvRQNIsWtidOSKuqmI4FSHpmYho8vZSuj/XptWOqVIk7QxcBNwOXEqS0ADNz9qrdQMG9Y97HmpySGJZrLnSOpMjYnDFPqAJrtBYnpQukf8ESRm44VyuF7hqIOmHEfGbhuOImARMSjepLEq5+1GSwc6LpdOYf5c+iuC1IiQtyzC/hWtNbc6ZS5L+QjK78OsRMS3reMrJC+uZZaSlWTAFumf/LZLBwEuIpJRaiFlcFK/S3ZTOWQdQBd2aua0mirW8wN0RcUVTFyStGxH/q3ZA1jQnNFYUNwAbZB2EtcrnJDU77ikiLmjuWo4UYrzTMpzYwrVJVYuiwhonM8VaG6pYv1s4obGiKMp3Zj9Jbzdxvkh7ALUFVqM4f2dNKfzgxDq4pbZYUdeGKto3oBMaK4qi/ACZFhEDsg6iwuZFxJlZB1FhXYs+y0nSH2n++y4i4vBqxlMp6dpQOwB3kNwOvgeY0Wh2l9UAJzSWGy3s5SRgrSqHY59e0X4xbMr7JNsfFNm4Js5tABxLUoUriqXWhpJUkF+givWt6ITG8qSlvZyKss/TmKwDqIK9Ja0QER9BstossAcwq0Ab/RV+llNE3NTwXFIP4GSSSsY5wB+yiqvc6mFtqKLwSsGWGxFxX1MP4L/AllnHVyavSOoFoMQfJb0t6YmSdXjy7k8kWzogaWNgAslmjT+QdHaGcZXTh1kHUA2SNpP0J+BW4AGgd0RcFhGF6n9E/DsiTkvX1jmOZB2sRyU9lHFon4GQKvfIgis0lkuS1iZZiG04ySyDouydcwwwOn0+HOgHbESy/PpFwPbZhFVWnSLi2fT5YcB1EXGUpPYkt2l+ml1oZfODlhLQIiwCKWkMMJikOnocyX5cHRp+mKVrCxVOydpQJ5J8v1qNcEJjuSFpdWAfktLvJiRJTI+I6JppYOW1sOFWDLAncHVEvEZS6j6vhdflSen4g52BkQAR8aGkomzAOYqknw2/qjYec5H7RSCBIST9OgH4UXqutL89sgiqWiLiY0nHAb/OOhZLOKGxPHmZZJXZU4EHIiIk7ZNxTOX2saTOJIMQvwScVXJt5WxCKrsnJI0C5gAbk8weQVLHTKMqr5OAFyNiHoCkw0jWLpkJnJFdWOUTEd2zjqEGFGtUbc55DI3lycnASsBlwE8l9cw4nko4jWRRspnA2Ih4CkDSjiRjhYrgO8CrJONodo2I99LzvSnO4O7/AxYApDs0nw1cBbxFsjN1IUnqKekUSU9mHUuV5Ha2U7I5ZeX+y6RP3pzS8iadUTEcOAjoRbKz7y0R8UymgZWJpHbA6hHxRsm5VUm+X9/JLjJrLUlTI2KL9PmlwCsRcUZ6/HhE9M8yvnJKK4oHktwK7keSvN1clH2PJM2n+eUiVo6IXN7pGDhoQNz38PiKvX+H9h29OaVZcyQdSzKT4vGIOAs4S1JfkuTmH0DuKzbpDKeRwMaSpgEnRMSciCjSZn/30vKCbF+qZjwV0rZkV/EvAUeUXCvEv7uSvkPyvdeVZOuRbwN/i4ifZxpYmUXE6lnHYK1TiG8sqxtdgYuBz0t6AngIeBAYFREnZxpZ+VxJMiX0XyRLrV8C7JtpROV3QhPntgZ+TDJOqgiuA+6T9CrJInv3w+Jp6m9lGVgZXUoy5f7r6cwfirPgXH0o2gAgJzSWGxFxAkA6vXcwsC3J7tRXSHozInpnGV+ZrF6yGd5ISbmf3ttYRCxeQTcdG/QzYEXgexHxj8wCK6OIOEvS3SS7bt8Rn9zbbwMclV1kZbU+ydIJF0hal6RKs0K2IVk9c0JjebQy0AFYI33MBQpxvx5YSdIAPvnlaeXS4yKsXwIg6SskicwHwFkRcW/GIZVdRDzcxLkXtZ9rAAAPIUlEQVRCjPMCiIhXSQboXyapK8mYtpclPU0ypq0oVdPCymoBvEpxQmO5IelyoA8wH3iE5JbTBaWDZwvgJeCCZo6DAqxfImki8DmSsUIT0nOLF6ErStJWdJK2bkjaImI2yQy1UelWFgdlGpzVJSc0licbkNyaeJZkDZPZwJuZRlRmEbFT1jFUwbvAO8D+6aNUIZK2OvFbYKnVkCPiP0ChBgYXkyjaKBonNJYbEbGbkhppH5LxMz8CNpf0OjAhIk7PNMAykNR4AHCQrNnyeETMzyCksquTpM3MqswJjeVKOrjySUlvkswWeYtki4AtSdajybthTZxbE+gn6fCIuKfaAZWbpKkk0+8fAh6MiJnZRmSfUg9JY5u7GBF7VTMYW37Fqs84obEckXQ0SWVmO+AjkinbE0imOhdiUHBEfLOp85I2JJlFslV1I6qIg0n+Hr8MnJ4uGvhQwyMiHskyOGu1V4Dzsw7CPotipTROaCxPugM3Asc17JFTLyJilqRCTImNiCeBJ0m3AEh3Tj8IOJZkYGnb7KKz5fBORNyXdRBmDZzQWG5ExPFZx5CVdObIgqzjKAdJbYEBfFJt60kyyPv3pLOeLBfekLReRLwEIOlQkg04ZwFnRMTrmUZnLZOnbZtZBUm6laW3BViTZIG2b1Q/oop4G3iaZKXZn0TE8xnHY59OR+BDWLwB5zkkiwb2J6m+NZ7BZlZRTmjMakvj3aYDeA14NiI+zCCeSvg2sE36/2+m69JMIJmpNifTyGx5tCmpwhwIXB4RNwE3SXo8w7gsByTtBlxEcov59xFxTqPrK5JsAzOI5N/AA5c1gcAJjVkNae2YBEkTImKbSsdTCRFxHcleR0hahWSG2nbA2ZLaR8SGWcZnrdau6BtwWmWkt50vJZkYMBuYKGlsREwvaXY48EZEbCzpIOBcksS5Wf6iM8unlbIO4LNIZzZtxSfjaIYAL5LMXLN8qIcNOAsrWVYvszE0WwIzIuK/AJL+AuwNlCY0ewNnpM9vBH4jSSX7oi3FCY1ZPuV2V2NJj5Gs+jyJZKr2+cDDEfFOpoHZcqmTDTgLa8rkx25fud2qa1fwI1aSNKnk+PKIuDx93oXkF5gGs1l6SYrFbSJioaS3gLVIFhptkhMaM6u2w4BpLf2mZflQ9A04iywidsvw45sqDTX+96A1bZbQ5lOHY2ZZyu18y4h4Augj6SpJkyRNTJ/3yzo2M6uK2UC3kuOuwNzm2khqB6wBtLgUgBMas3w6JOsAPi1JewO3APcB3yKZ7XQfyeyYvbOMzcyqYiLQS9JGktqTLKzZeBuNsSTVXEiWALhnWVVdueprVjskHQ6sGREj0+M5wOokFZkfR8RlWcZXDuleTns3noIpqTvwt4jYIoOwzKyKJO0BXEgybfvKdEzWmcCkiBgraSXgGpJFOF8HDmoYRNzsezqhMasd6Zosu0XEa+nxYxExIP3mviMidsg2ws9O0vSI6L2818zMWuJbTma1pU1DMpMaAxARHwArZxNS2X0kaYPGJ9MNOBdmEI+ZFYBnOZnVljVKDyLiVwCS2pBMWSyC04G7JP0KmEwyc2EI8BPgpCwDM7P88i0nsxoi6bfA6xFxaqPzvwTWjojvZRNZeUnaAvgR0IdkfNBTwKiImJppYGaWW05ozGpIuoLu70kqFg0/3LcgWYTu2158zsysaU5ozGqQpB4k1QuA6RHxXJbxlJukw4Cjgc+np54GLo6Iq7OLyszyzGNozGpIyWDZhXxSoVl8PiJeyCKucpJ0KHAscDwwheSW00BgpCSc1JjZp+EKjVkNkTSNZJBs6UrAAXwOWCci2mYSWBlJephkTYmZjc53B/4SEVtnEJaZ5ZwrNGY1JCL6lh6nP+RPAnYBfpVBSJXQoXEyAxARMyV1yCAeMysAr0NjVoMk9ZI0GvgHydTm3hFxSbZRlc37n/KamVmzfMvJrIZI2hw4hWRA8HnAdRGxKNuoykvSe8CMpi4BPSJi1SqHZGYF4ITGrIZIWgS8CNwGLJXIRMTRVQ+qzNIVgZsVEbOqFYuZFYfH0JjVlsNJBgEXVmsTFkkTImKbSsdjZsXgCo2Z1aSGjTmzjsPM8sEVGrMaIulWWqjQRMReVQwna/5ty8xazQmNWW0ZlXUAZmZ55ITGrLa0j4g7m7og6VzgvirHkyUtu4mZWcLr0JjVlkslDS09IalNuibNFtmElJlDsg7AzPLDCY1ZbdkVOF/SvgCSVgbGAu2BYVkGVi6SDpd0YsnxHElvS5ov6ciG8xHxZDYRmlkeeZaTWY2R1BW4HbiEpErxSEQcn21U5SNpIrBbRLyWHj8WEQMkrQTcERE7ZBuhmeWRx9CY1RBJA9OnPwauBu4E/tRwPiKmZBVbGbVpSGZSYwAi4oO0ImVmttxcoTGrIZLubeFyRMTOVQumQiTNiIiNmzjfBpgRET0yCMvMcs4JjVlOSNo6Ih7OOo7PStJvgdcj4tRG538JrB0R38smMjPLMyc0Zjkh6YWI2CDrOD4rSasCvweGAFPT01sAk4BvR8Q7WcVmZvnlhMYsJyS9GBHdso6jXCT1INlVHGB6RDyXZTxmlm9OaMxyokAVmhb7EBEvVCsWMysOz3IyqyEt7OUkYK0qh1Mpt5H0sXQl4AA+B6wDtM0iKDPLN1dozGqIpB1buh4Rhdv6QFJ34CRgF+DiiLgk04DMLJec0JjlgKRuwEERMTLrWMpFUi/gFGAr4Hzgqoj4KNuozCyvvPWBWY2StLakIyX9CxgPrJtxSGUhaXNJ1wE3AXcBm0fE753MmNln4QqNWQ2RtDqwD/B1YBPgFuDAiOiaaWBlJGkR8CLJWJpFja9HxNFVD8rMcs+Dgs1qy8vAo8CpwAMREZL2yTimcjucpgc+m5l9aq7QmNUQSccBBwGrAn8Grgfu9HYAZmYtc0JjVoPSReeGkyQ3vYDTgVsi4plMAyuDFqamAxARe1UxHDMrCCc0ZjVE0rHAA8DjEbEwPdeXJLk5MCJ6ZhlfOdTj1HQzqzyPoTGrLV2Bi4HPS3oCeAh4EBgVESdnGln5tI+IO5u6IOlcwAmNmS03V2jMapCk9sBgYFtgm/TxZkT0zjSwMpD0DHBcRNxWcq4NcCWwXkTslllwZpZbrtCY1aaVgQ7AGuljLjAt04jKZ1fgn5JWjIibJa0MjAHeBoZlG5qZ5ZUrNGY1RNLlJDtQzwceAR4GHo6INzINrMwkdQVuBy4BDgEeiYjjs43KzPLMKwWb1ZYNgBWBl4A5wGzgzUwjKjNJA0k2ofwxcBbJInt/kjQwvWZmttxcoTGrMZJEUqXZNn1sDrwOTIiI07OMrRwk3dvC5YiInasWjJkVhhMasxqV3pbZjiSp2RNYKyI6ZhtVZUnaOiIezjoOM8sfJzRmNUTS0SQJzHbARyRTtiek/58WER9nGF7FSXohIjbIOg4zyx/PcjKrLd2BG0mmNc/LOJYsKOsAzCyfXKExs5rhCo2ZfVqu0JhZVbWwl5OAtaocjpkVhCs0ZlZV3svJzCrBCY2Z1QRJ3YCDImJk1rGYWf54YT0zy4yktSUdKelfwHhg3YxDMrOc8hgaM6sqSasD+wBfBzYBbgF6RETXTAMzs1zzLSczqypJ7wOPAqcCD0RESPpvRPTIODQzyzHfcjKzajsZWAm4DPippJ4Zx2NmBeAKjZllQlIPYDhwENALOB24JSKeyTQwM8slJzRmVlWSjgUeAB6PiIXpub4kyc2BEeGKjZktNyc0ZlZVkkaR7Ff1eeAJ4CHSPasi4vUsYzOz/HJCY2aZkNQeGEyS3GyTPt6MiN6ZBmZmueRp22aWlZWBDsAa6WMuMC3TiMwst1yhMbOqknQ50AeYDzwCPAw8HBFvZBqYmeWap22bWbVtAKwIvATMAWYDb2YakZnlnis0ZlZ1kkRSpdk2fWwOvE4yMPj0LGMzs3xyQmNmmZHUFdiOJKnZE1grIjpmG5WZ5ZETGjOrKklHkyQw2wEfkU7ZTv8/LSI+zjA8M8spz3Iys2rrDtwIHBcR8zKOxcwKwhUaMzMzyz3PcjIzM7Pcc0JjZmZmueeExsyqQtIiSY9LelLSGEmrfIb32knSuPT5XpJ+0kLbjpK+/yk+4wxJJ7T2fKM2oyXtvxyf1V3Sk8sbo5l9wgmNmVXL+xHRPyI2Bz4Evld6UYnl/jcpIsZGxDktNOkILHdCY2b54oTGzLJwP7BxWpl4WtJvgSlAN0m7SpogaUpayVkNQNJukv4t6QFg34Y3kjRC0m/S5+tKukXS1PSxLXAO0DOtDo1M250oaaKkJyT9vOS9TpH0H0l3AZsuqxOSvpO+z1RJNzWqOu0i6X5Jz0jaM23fVtLIks/+7mf9gzSzhBMaM6sqSe2A3flkI8pNgasjYgDwLnAqsEtEDAQmAcdLWgm4AhgGbA+s18zbXwzcFxFbAAOBp4CfAM+l1aETJe0K9AK2BPoDgyTtIGkQcBAwgCRhGtKK7twcEUPSz3saOLzkWndgR2Ao8H9pHw4H3oqIIen7f0fSRq34HDNbBq9DY2bVsrKkx9Pn9wN/ANYHZkXEw+n5rYHewIPJ7gi0J1l07/PA8xHxLICkPwFHNPEZOwOHAkTEIuAtSZ0atdk1fTyWHq9GkuCsDtwSEe+lnzG2FX3aXNIvSW5rrQbcXnLthnSRwGcl/Tftw65Av5LxNWukn/1MKz7LzFrghMbMquX9iOhfeiJNWt4tPQXcGRHDG7XrD5Rr0SwBZ0fE7xp9xrGf4jNGA1+NiKmSRgA7lVxr/F6RfvZREVGa+CCp+3J+rpk14ltOZlZLHga2k7QxgKRVJG0C/BvYSFLPtN3wZl5/N3Bk+tq2kjoA80mqLw1uB75VMjani6R1gH8B+0haWdLqJLe3lmV1YJ6kFYCDG107QFKbNOYewH/Szz4ybY+kTSSt2orPMbNlcIXGzGpGRLySVjquk7RievrUiHhG0hHAbZJeBR4g2aG7sWOAyyUdDiwCjoyICZIeTKdF/yMdR7MZMCGtEL0DfCMipki6HngcmEVyW2xZfgY8krafxpKJ03+A+4B1ge9FxAeSfk8ytmZKuuP4K8BXW/enY2Yt8dYHZmZmlnu+5WRmZma554TGzMzMcs8JjZmZmeWeExozMzPLPSc0ZmZmlntOaMzMzCz3nNCYmZlZ7jmhMTMzs9z7f1FavAPPh81dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "labels=['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS','SITTING','STANDING','LAYING']\n",
    "plot_confusion_matrix(cm, classes=labels, \n",
    "                      normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.5 Now work with RAW features only, in your HAR. And output of the lstms should be sent to conv layers and then apply some dense layers and finally a soft max layer.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 126, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                99250     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 111,140\n",
      "Trainable params: 111,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "# 1st use LSTM and then output of LSTM to  CONV layers\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Add maxpooling and flatten layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "# Output of  conv layers  to dense layer, output of dense layer to softmax layer \n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.3692 - accuracy: 0.8501 - val_loss: 0.3845 - val_accuracy: 0.8931\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1585 - accuracy: 0.9357 - val_loss: 0.5315 - val_accuracy: 0.8826\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1303 - accuracy: 0.9471 - val_loss: 0.6576 - val_accuracy: 0.9013\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1301 - accuracy: 0.9486 - val_loss: 0.6384 - val_accuracy: 0.9077\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1116 - accuracy: 0.9563 - val_loss: 0.5395 - val_accuracy: 0.9026\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1127 - accuracy: 0.9535 - val_loss: 0.8545 - val_accuracy: 0.8999\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1003 - accuracy: 0.9587 - val_loss: 0.6561 - val_accuracy: 0.8968\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1031 - accuracy: 0.9600 - val_loss: 0.7699 - val_accuracy: 0.8918\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1153 - accuracy: 0.9589 - val_loss: 0.6547 - val_accuracy: 0.9084\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0914 - accuracy: 0.9612 - val_loss: 0.6956 - val_accuracy: 0.9046\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1038 - accuracy: 0.9596 - val_loss: 0.6759 - val_accuracy: 0.9057\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0976 - accuracy: 0.9627 - val_loss: 0.6510 - val_accuracy: 0.8938\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0955 - accuracy: 0.9619 - val_loss: 0.8151 - val_accuracy: 0.9026\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0965 - accuracy: 0.9649 - val_loss: 0.5930 - val_accuracy: 0.9009\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0946 - accuracy: 0.9644 - val_loss: 0.6105 - val_accuracy: 0.9009\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0953 - accuracy: 0.9637 - val_loss: 0.6110 - val_accuracy: 0.8928\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0847 - accuracy: 0.9645 - val_loss: 0.6800 - val_accuracy: 0.8877\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.0900 - accuracy: 0.9674 - val_loss: 0.5505 - val_accuracy: 0.8901\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0926 - accuracy: 0.9693 - val_loss: 0.6652 - val_accuracy: 0.9043\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 18s 3ms/step - loss: 0.1022 - accuracy: 0.9709 - val_loss: 1.0711 - val_accuracy: 0.9026\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.0894 - accuracy: 0.9671 - val_loss: 0.7108 - val_accuracy: 0.8931\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 18s 3ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.6325 - val_accuracy: 0.9050\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 18s 3ms/step - loss: 0.0937 - accuracy: 0.9697 - val_loss: 0.4771 - val_accuracy: 0.9189\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0961 - accuracy: 0.9724 - val_loss: 0.4298 - val_accuracy: 0.9223\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.0824 - accuracy: 0.9733 - val_loss: 0.7755 - val_accuracy: 0.9019\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.0916 - accuracy: 0.9718 - val_loss: 0.6355 - val_accuracy: 0.9206\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.0896 - accuracy: 0.9725 - val_loss: 0.4728 - val_accuracy: 0.9111\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0821 - accuracy: 0.9748 - val_loss: 0.6026 - val_accuracy: 0.9158\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0677 - accuracy: 0.9744 - val_loss: 0.7449 - val_accuracy: 0.9172\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 18s 3ms/step - loss: 0.0782 - accuracy: 0.9748 - val_loss: 0.5481 - val_accuracy: 0.9182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63c5395c0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  5      372       114        0                   0   \n",
      "STANDING                 0       60       469        3                   0   \n",
      "WALKING                  0        0         1      489                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 389   \n",
      "WALKING_UPSTAIRS         0        0         0       19                   2   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            6  \n",
      "WALKING_DOWNSTAIRS                30  \n",
      "WALKING_UPSTAIRS                 450  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 290us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5481175343919985, 0.9182218909263611]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decrease dropout and tried other variations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 126, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                99250     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 111,140\n",
      "Trainable params: 111,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "# 1st use LSTM and then output of LSTM to  CONV layers\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Add maxpooling and flatten layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "# Output of  conv layers  to dense layer, output of dense layer to softmax layer \n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.4346 - accuracy: 0.8316 - val_loss: 0.4471 - val_accuracy: 0.8867\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1599 - accuracy: 0.9363 - val_loss: 0.3654 - val_accuracy: 0.9019\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1304 - accuracy: 0.9483 - val_loss: 0.4729 - val_accuracy: 0.9036\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 18s 3ms/step - loss: 0.1197 - accuracy: 0.9501 - val_loss: 0.4634 - val_accuracy: 0.9155\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1152 - accuracy: 0.9513 - val_loss: 0.5189 - val_accuracy: 0.9298\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1043 - accuracy: 0.9558 - val_loss: 0.5348 - val_accuracy: 0.9291\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1103 - accuracy: 0.9591 - val_loss: 0.6338 - val_accuracy: 0.9063\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0963 - accuracy: 0.9585 - val_loss: 0.6357 - val_accuracy: 0.9213\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1077 - accuracy: 0.9574 - val_loss: 0.8853 - val_accuracy: 0.8992\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1017 - accuracy: 0.9601 - val_loss: 0.6541 - val_accuracy: 0.9077\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0981 - accuracy: 0.9604 - val_loss: 0.6410 - val_accuracy: 0.9046\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0994 - accuracy: 0.9633 - val_loss: 0.6200 - val_accuracy: 0.9121\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1157 - accuracy: 0.9641 - val_loss: 0.8546 - val_accuracy: 0.9131\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0970 - accuracy: 0.9621 - val_loss: 0.7290 - val_accuracy: 0.9033\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0999 - accuracy: 0.9671 - val_loss: 0.9121 - val_accuracy: 0.9006\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0863 - accuracy: 0.9648 - val_loss: 1.0077 - val_accuracy: 0.8897\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1005 - accuracy: 0.9640 - val_loss: 1.0764 - val_accuracy: 0.8924\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0948 - accuracy: 0.9649 - val_loss: 1.0773 - val_accuracy: 0.9030\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0837 - accuracy: 0.9664 - val_loss: 0.9049 - val_accuracy: 0.9131\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1002 - accuracy: 0.9665 - val_loss: 0.7059 - val_accuracy: 0.9277\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0901 - accuracy: 0.9693 - val_loss: 0.7491 - val_accuracy: 0.9104\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0795 - accuracy: 0.9697 - val_loss: 0.8270 - val_accuracy: 0.9111\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0827 - accuracy: 0.9701 - val_loss: 1.0694 - val_accuracy: 0.9108\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0727 - accuracy: 0.9712 - val_loss: 0.8130 - val_accuracy: 0.9264\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0918 - accuracy: 0.9725 - val_loss: 0.9463 - val_accuracy: 0.9158\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0777 - accuracy: 0.9721 - val_loss: 1.1119 - val_accuracy: 0.9125\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0759 - accuracy: 0.9706 - val_loss: 1.3036 - val_accuracy: 0.9019\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.9760 - val_accuracy: 0.9250\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1036 - accuracy: 0.9739 - val_loss: 1.0356 - val_accuracy: 0.9087\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0705 - accuracy: 0.9757 - val_loss: 1.0847 - val_accuracy: 0.9206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x6458fcb70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 414us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.08474476597534, 0.9205971956253052]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LSTM with Conv1D slightly increase performance.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add two layer dropout</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 126, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 126, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 124, 32)           3104      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                99250     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 111,140\n",
      "Trainable params: 111,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "# 1st use LSTM and then output of LSTM to  CONV layers\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Add maxpooling and flatten layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "# Output of  conv layers  to dense layer, output of dense layer to softmax layer \n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.5253 - accuracy: 0.7854 - val_loss: 0.5624 - val_accuracy: 0.8208\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 18s 3ms/step - loss: 0.1975 - accuracy: 0.9232 - val_loss: 0.5013 - val_accuracy: 0.8914\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1451 - accuracy: 0.9423 - val_loss: 0.5495 - val_accuracy: 0.8677\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1338 - accuracy: 0.9472 - val_loss: 0.3797 - val_accuracy: 0.9030\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1304 - accuracy: 0.9478 - val_loss: 0.4006 - val_accuracy: 0.8877\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1229 - accuracy: 0.9484 - val_loss: 0.3259 - val_accuracy: 0.9108\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1191 - accuracy: 0.9528 - val_loss: 0.3226 - val_accuracy: 0.9223\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1149 - accuracy: 0.9529 - val_loss: 0.3726 - val_accuracy: 0.9043\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1154 - accuracy: 0.9543 - val_loss: 0.3421 - val_accuracy: 0.9128\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1055 - accuracy: 0.9585 - val_loss: 0.5777 - val_accuracy: 0.9108\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1067 - accuracy: 0.9581 - val_loss: 0.9684 - val_accuracy: 0.8965\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1140 - accuracy: 0.9581 - val_loss: 0.5287 - val_accuracy: 0.8958\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1095 - accuracy: 0.9604 - val_loss: 0.4963 - val_accuracy: 0.9040\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1032 - accuracy: 0.9595 - val_loss: 0.5505 - val_accuracy: 0.9125\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1031 - accuracy: 0.9607 - val_loss: 0.6846 - val_accuracy: 0.9155\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1036 - accuracy: 0.9607 - val_loss: 0.7777 - val_accuracy: 0.9067\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.0914 - accuracy: 0.9635 - val_loss: 1.1068 - val_accuracy: 0.9009\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1009 - accuracy: 0.9611 - val_loss: 1.8117 - val_accuracy: 0.9050\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1219 - accuracy: 0.9630 - val_loss: 0.9199 - val_accuracy: 0.9043\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0938 - accuracy: 0.9641 - val_loss: 1.2955 - val_accuracy: 0.8904\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.0924 - accuracy: 0.9676 - val_loss: 1.3183 - val_accuracy: 0.8721\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1005 - accuracy: 0.9660 - val_loss: 1.2037 - val_accuracy: 0.8850\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0913 - accuracy: 0.9656 - val_loss: 1.1553 - val_accuracy: 0.8904\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 18s 3ms/step - loss: 0.0860 - accuracy: 0.9661 - val_loss: 1.2973 - val_accuracy: 0.9101\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1043 - accuracy: 0.9660 - val_loss: 1.2217 - val_accuracy: 0.8948\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1022 - accuracy: 0.9679 - val_loss: 1.5939 - val_accuracy: 0.8914\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0987 - accuracy: 0.9690 - val_loss: 1.0499 - val_accuracy: 0.8904\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0944 - accuracy: 0.9669 - val_loss: 0.8462 - val_accuracy: 0.8901\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.0910 - accuracy: 0.9689 - val_loss: 0.7629 - val_accuracy: 0.8935\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.0978 - accuracy: 0.9660 - val_loss: 0.7633 - val_accuracy: 0.8955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64453d9e8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  6      387        95        0                   0   \n",
      "STANDING                 0       77       452        0                   1   \n",
      "WALKING                  0        0         1      436                  30   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 418   \n",
      "WALKING_UPSTAIRS         0        0         0        8                  27   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            3  \n",
      "STANDING                           2  \n",
      "WALKING                           29  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 436  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 2s 742us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7633403087432127, 0.8954869508743286]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LSTM with Conv1D and 2 layer dropout doesn't increase performance much.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Conclusion </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Models Output </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+---------------------+---------------------+\n",
      "|     LSTM Layer     | Dropout |         Loss        |       Accuracy      |\n",
      "+--------------------+---------+---------------------+---------------------+\n",
      "|         32         |   0.5   | 0.41655886096877154 |  0.8954869508743286 |\n",
      "|         64         |   0.5   | 0.35375094639873494 |  0.9148286581039429 |\n",
      "|         64         |   0.7   |         nan         | 0.16830675303936005 |\n",
      "|         32         |   0.7   |  0.596762544016313  |  0.8381404876708984 |\n",
      "|         64         |   0.6   |  0.4956902541945778 |  0.9060060977935791 |\n",
      "|         32         |   0.6   |  0.5602035771178105 |  0.8812351822853088 |\n",
      "|       64+32        |  2*0.7  |         nan         | 0.16830675303936005 |\n",
      "|       64+32        |  2*0.6  |         nan         | 0.16830675303936005 |\n",
      "|       64+32        |  2*0.5  |  0.6456601167650766 |  0.900237500667572  |\n",
      "|       64+32        |   0.7   |         nan         | 0.16830675303936005 |\n",
      "|       64+32        |   0.6   |  0.5375813010956876 |  0.9053274393081665 |\n",
      "|       64+32        |   0.5   |  0.3804781971405892 |  0.9141499996185303 |\n",
      "|       64+16        |   0.5   |  0.5414807511955393 |  0.9056667685508728 |\n",
      "|       32+16        |   0.5   |  0.3589311393391746 |  0.922633171081543  |\n",
      "|        32+8        |   0.5   |  0.3761567989555303 |  0.7539871335029602 |\n",
      "|        32+8        |   0.5   |  0.3761567989555303 |  0.7539871335029602 |\n",
      "|        32+8        |   0.5   |  0.3761567989555303 |  0.7539871335029602 |\n",
      "|       32+16        |   0.6   | 0.36157595883878874 |  0.9100780487060547 |\n",
      "|       32+16        |   0.4   | 0.39125852214684165 |  0.9066847562789917 |\n",
      "|        128         |   0.25  | 0.31214076887265046 |  0.9256871342658997 |\n",
      "| Divide and Conquer |   N/A   |          -          |  0.9460468272819816 |\n",
      "+--------------------+---------+---------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['LSTM Layer', 'Dropout', 'Loss', 'Accuracy']\n",
    "\n",
    "table.add_row([32, 0.5, 0.41655886096877154, 0.8954869508743286])\n",
    "table.add_row([64, 0.5, 0.35375094639873494, 0.9148286581039429])\n",
    "table.add_row([64, 0.7, 'nan', 0.16830675303936005])\n",
    "table.add_row([32, 0.7, 0.596762544016313, 0.8381404876708984])\n",
    "table.add_row([64, 0.6, 0.4956902541945778, 0.9060060977935791])\n",
    "table.add_row([32, 0.6, 0.5602035771178105, 0.8812351822853088])\n",
    "table.add_row(['64+32', '2*0.7', 'nan', 0.16830675303936005])\n",
    "table.add_row(['64+32', '2*0.6', 'nan', 0.16830675303936005])\n",
    "table.add_row(['64+32', '2*0.5', 0.6456601167650766, 0.900237500667572])\n",
    "table.add_row(['64+32', 0.7, 'nan', 0.16830675303936005])\n",
    "table.add_row(['64+32', 0.6, 0.5375813010956876, 0.9053274393081665])\n",
    "table.add_row(['64+32', 0.5, 0.3804781971405892, 0.9141499996185303])\n",
    "table.add_row(['64+16', 0.5, 0.5414807511955393, 0.9056667685508728])\n",
    "table.add_row(['32+16', 0.5, 0.3589311393391746, 0.922633171081543])\n",
    "table.add_row(['32+8', 0.5, 0.3761567989555303, 0.7539871335029602])\n",
    "table.add_row(['32+8', 0.5, 0.3761567989555303, 0.7539871335029602])\n",
    "table.add_row(['32+8', 0.5, 0.3761567989555303, 0.7539871335029602])\n",
    "table.add_row(['32+16', 0.6, 0.36157595883878874, 0.9100780487060547])\n",
    "table.add_row(['32+16', 0.4, 0.39125852214684165, 0.9066847562789917])\n",
    "table.add_row(['128', 0.25, 0.31214076887265046, 0.9256871342658997])\n",
    "table.add_row(['Divide and Conquer', 'N/A', '-', 0.9460468272819816])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Steps I followed</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Did EDA on dataset\n",
    "- Run classical machine learning models on 561 handcrafted features\n",
    "- Run different LSTMs on raw time series data\n",
    "- Tried 2 LSTMs with larger dropout, increase layer of LSTM from 32 to 64\n",
    "- Above table contains different permutation and combination of LSTM that i tried\n",
    "- Implement Divide and Conquer technique for classifying Static and Dynamic Activities and Merge Models for Activities Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.3 Divide and Conquer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First classify static and dynamic activities, if label > 3 then static else dynamic\n",
    "- Classify static activities (Sitting, Standing and Laying)\n",
    "- Classify dynamic activities (Walking, Walking Upstairs and Walking Downstairs)\n",
    "- Classify whole data on above three models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.4 Best Model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divide and Conquer gives me 94.60% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
